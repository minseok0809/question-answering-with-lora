{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "teHzLo4owK3j"
      },
      "source": [
        "## LMQG Model Development (Libra Device 1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "<b>Model</b>\n",
        "<br>T5 Small / BART Base / T5 Base / T5 Large / BART Large\n",
        "<br>Gold QA (i.e., the model using the human-labeled gold\n",
        "annotations)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "<b>QAG approaches</b>\n",
        "<br>End2Endv / MultiTask / Pipeline"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "<b>Dataset</b>\n",
        "<br>SQuADShifts (Amazon / Wiki / NYT / Reddit)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "<b>Experiment</b>\n",
        "<br>All / Amazon / Wiki / NYT / Reddit"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "L6m9o9YV0j7O"
      },
      "outputs": [],
      "source": [
        "%pip install lmqg\n",
        "%pip install peft\n",
        "%pip install easydict\n",
        "%pip install termcolor\n",
        "%pip install openpyxl\n",
        "%pip install ipywidgets\n",
        "!python -m spacy download en"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "XrYqvzLjZwev"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import json\n",
        "import torch\n",
        "from pprint import pprint\n",
        "# from termcolor import coloredg\n",
        "from lmqg import TransformersQG"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "True\n",
            "2\n",
            "NVIDIA GeForce RTX 4090\n"
          ]
        }
      ],
      "source": [
        "print(torch.cuda.is_available())\n",
        "print(torch.cuda.device_count())\n",
        "print(torch.cuda.get_device_name(torch.cuda.current_device()))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'/'"
            ]
          },
          "execution_count": 3,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "pwd"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "/workspace\n"
          ]
        }
      ],
      "source": [
        "cd workspace"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [],
      "source": [
        "import torch\n",
        "torch.cuda.empty_cache()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [],
      "source": [
        "import torch, gc\n",
        "gc.collect()\n",
        "torch.cuda.empty_cache()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {},
      "outputs": [],
      "source": [
        "os.environ[\"CUDA_DEVICE_ORDER\"]=\"PCI_BUS_ID\"\n",
        "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"1\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mminseok0809\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "execution_count": 8,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import wandb\n",
        "\n",
        "wandb.login()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Flan T5 Small Model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Original Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "!python -m lm-question-generation.lmqg.grid_searcher_flan_t5_small_squad_qg"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {},
      "outputs": [],
      "source": [
        "wandb.finish()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Lora Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "!python -m lm-question-generation.lmqg.grid_searcher_flan_t5_small_squad_qg_lora_r8_al16"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "!python -m lm-question-generation.lmqg.grid_searcher_flan_t5_small_squad_qg_lora_r16_al16"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "!python -m lm-question-generation.lmqg.grid_searcher_flan_t5_small_squad_qg_lora_r32_al16"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "!python -m lm-question-generation.lmqg.grid_searcher_flan_t5_small_squad_qg_lora_r64_al16"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "!python -m lm-question-generation.lmqg.grid_searcher_flan_t5_small_squad_qg_lora_r128_al16"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "!python -m lm-question-generation.lmqg.grid_searcher_flan_t5_small_squad_qg_lora_r8_al32"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "!python -m lm-question-generation.lmqg.grid_searcher_flan_t5_small_squad_qg_lora_r16_al32"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "!python -m lm-question-generation.lmqg.grid_searcher_flan_t5_small_squad_qg_lora_r32_al32"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "!python -m lm-question-generation.lmqg.grid_searcher_flan_t5_small_squad_qg_lora_r64_al32"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "!python -m lm-question-generation.lmqg.grid_searcher_flan_t5_small_squad_qg_lora_r128_al32"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {},
      "outputs": [],
      "source": [
        "wandb.finish()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Flan T5 Large Model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Original Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "!python -m lm-question-generation.lmqg.grid_searcher_flan_t5_large_squad_qg"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "wandb.finish()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Lora Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "!python -m lm-question-generation.lmqg.grid_searcher_flan_t5_large_squad_qg_lora_r1_al32_training "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "!python -m lm-question-generation.lmqg.grid_searcher_flan_t5_large_squad_qg_lora_r1_al32_evaluation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "!python -m lm-question-generation.lmqg.grid_searcher_flan_t5_large_squad_qg_lora_r2_al32_training "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "!python -m lm-question-generation.lmqg.grid_searcher_flan_t5_large_squad_qg_lora_r2_al32_evaluation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "!python -m lm-question-generation.lmqg.grid_searcher_flan_t5_large_squad_qg_lora_r4_al32_training "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "!python -m lm-question-generation.lmqg.grid_searcher_flan_t5_large_squad_qg_lora_r4_al32_evaluation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "!python -m lm-question-generation.lmqg.grid_searcher_flan_t5_large_squad_qg_lora_r8_al32_training"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "!python -m lm-question-generation.lmqg.grid_searcher_flan_t5_large_squad_qg_lora_r8_al32_evaluation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "!python -m lm-question-generation.lmqg.grid_searcher_flan_t5_large_squad_qg_lora_r16_al32_training"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "!python -m lm-question-generation.lmqg.grid_searcher_flan_t5_large_squad_qg_lora_r16_al32_evaluation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mminseok0809\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: wandb version 0.15.10 is available!  To upgrade, please run:\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:  $ pip install wandb --upgrade\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.15.9\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Run data is saved locally in \u001b[35m\u001b[1m/workspace/wandb/run-20230910_124731-pukh4mie\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Run \u001b[1m`wandb offline`\u001b[0m to turn off syncing.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Syncing run \u001b[33mflan_t5_large_squad_qg_lora_r32_al32\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: ⭐️ View project at \u001b[34m\u001b[4mhttps://wandb.ai/minseok0809/lmqg_qg_squad\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: 🚀 View run at \u001b[34m\u001b[4mhttps://wandb.ai/minseok0809/lmqg_qg_squad/runs/pukh4mie\u001b[0m\n",
            "/opt/conda/lib/python3.8/site-packages/transformers/models/auto/tokenization_auto.py:631: FutureWarning: The `use_auth_token` argument is deprecated and will be removed in v5 of Transformers.\n",
            "  warnings.warn(\n",
            "/opt/conda/lib/python3.8/site-packages/transformers/models/auto/configuration_auto.py:995: FutureWarning: The `use_auth_token` argument is deprecated and will be removed in v5 of Transformers.\n",
            "  warnings.warn(\n",
            "/opt/conda/lib/python3.8/site-packages/transformers/modeling_utils.py:2310: FutureWarning: The `use_auth_token` argument is deprecated and will be removed in v5 of Transformers.\n",
            "  warnings.warn(\n",
            "/opt/conda/lib/python3.8/site-packages/transformers/utils/hub.py:373: FutureWarning: The `use_auth_token` argument is deprecated and will be removed in v5 of Transformers.\n",
            "  warnings.warn(\n",
            "You are resizing the embedding layer without providing a `pad_to_multiple_of` parameter. This means that the new embeding dimension will be 32101. This might induce some performance reduction as *Tensor Cores* will not be available. For more details  about this, or help on choosing the correct value for resizing, refer to this guide: https://docs.nvidia.com/deeplearning/performance/dl-performance-matrix-multiplication/index.html#requirements-tc\n",
            "\n",
            "\n",
            "trainable model parameters: 9437184\n",
            "all model parameters: 792531968\n",
            "percentage of trainable model parameters: 1.19% \n",
            "\n",
            "/opt/conda/lib/python3.8/site-packages/datasets/load.py:2072: FutureWarning: 'use_auth_token' was deprecated in favor of 'token' in version 2.14.0 and will be removed in 3.0.0.\n",
            "You can remove this warning by passing 'token=False' instead.\n",
            "  warnings.warn(\n",
            "\n",
            "\n",
            "Epoch 1: 100%|██████████████████████████| 18792/18792 [1:07:19<00:00,  4.65it/s]\n",
            "Loss :   7.6817\n",
            "\n",
            "\n",
            "Epoch 2: 100%|██████████████████████████| 18792/18792 [1:07:20<00:00,  4.65it/s]\n",
            "Loss :   0.8077\n",
            "\n",
            "\n",
            "Epoch 3: 100%|██████████████████████████| 18792/18792 [1:07:30<00:00,  4.64it/s]\n",
            "Loss :   0.7362\n",
            "\n",
            "\n",
            "Epoch 4: 100%|██████████████████████████| 18792/18792 [1:07:26<00:00,  4.64it/s]\n",
            "Loss :   0.7048\n",
            "\n",
            "\n",
            "Epoch 5: 100%|██████████████████████████| 18792/18792 [1:07:18<00:00,  4.65it/s]\n",
            "Loss :   0.6777\n",
            "\n",
            "\n",
            "Epoch 6: 100%|██████████████████████████| 18792/18792 [1:07:24<00:00,  4.65it/s]\n",
            "Loss :   0.655\n",
            "\n",
            "\n",
            "Epoch 7: 100%|██████████████████████████| 18792/18792 [1:07:23<00:00,  4.65it/s]\n",
            "Loss :   0.6403\n",
            "\n",
            "\n",
            "Epoch 8: 100%|██████████████████████████| 18792/18792 [1:07:20<00:00,  4.65it/s]\n",
            "Loss :   0.6308\n",
            "\n",
            "\n",
            "Epoch 9: 100%|██████████████████████████| 18792/18792 [1:07:24<00:00,  4.65it/s]\n",
            "Loss :   0.6245\n",
            "\n",
            "\n",
            "Epoch 10: 100%|█████████████████████████| 18792/18792 [1:07:18<00:00,  4.65it/s]\n",
            "Loss :   0.6192\n",
            "\n",
            "\n",
            "Epoch 11: 100%|█████████████████████████| 18792/18792 [1:07:29<00:00,  4.64it/s]\n",
            "Loss :   0.6146\n",
            "\n",
            "\n",
            "Epoch 12: 100%|█████████████████████████| 18792/18792 [1:07:25<00:00,  4.65it/s]\n",
            "Loss :   0.6102\n",
            "\n",
            "\n",
            "Epoch 13: 100%|█████████████████████████| 18792/18792 [1:07:28<00:00,  4.64it/s]\n",
            "Loss :   0.6068\n",
            "\n",
            "\n",
            "Epoch 14: 100%|█████████████████████████| 18792/18792 [1:07:31<00:00,  4.64it/s]\n",
            "Loss :   0.6039\n",
            "\n",
            "\n",
            "Epoch 15: 100%|█████████████████████████| 18792/18792 [1:07:31<00:00,  4.64it/s]\n",
            "Loss :   0.6001\n",
            "\n",
            "\n",
            "Epoch 16: 100%|█████████████████████████| 18792/18792 [1:07:30<00:00,  4.64it/s]\n",
            "Loss :   0.5976\n",
            "\n",
            "\n",
            "Epoch 17: 100%|█████████████████████████| 18792/18792 [1:07:35<00:00,  4.63it/s]\n",
            "Loss :   0.5947\n",
            "\n",
            "\n",
            "Epoch 18: 100%|█████████████████████████| 18792/18792 [1:07:37<00:00,  4.63it/s]\n",
            "Loss :   0.5917\n",
            "\n",
            "\n",
            "Epoch 19: 100%|█████████████████████████| 18792/18792 [1:07:27<00:00,  4.64it/s]\n",
            "Loss :   0.5893\n",
            "\n",
            "\n",
            "Epoch 20: 100%|█████████████████████████| 18792/18792 [1:07:19<00:00,  4.65it/s]\n",
            "Loss :   0.587\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Waiting for W&B process to finish... \u001b[32m(success).\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: | 0.062 MB of 0.062 MB uploaded (0.000 MB deduped)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Run history:\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: loss █▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Run summary:\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: loss 0.58704\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: 🚀 View run \u001b[33mflan_t5_large_squad_qg_lora_r32_al32\u001b[0m at: \u001b[34m\u001b[4mhttps://wandb.ai/minseok0809/lmqg_qg_squad/runs/pukh4mie\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Find logs at: \u001b[35m\u001b[1m./wandb/run-20230910_124731-pukh4mie/logs\u001b[0m\n"
          ]
        }
      ],
      "source": [
        "!python -m lm-question-generation.lmqg.grid_searcher_flan_t5_large_squad_qg_lora_r32_al32_training"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mminseok0809\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: wandb version 0.15.10 is available!  To upgrade, please run:\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:  $ pip install wandb --upgrade\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.15.9\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Run data is saved locally in \u001b[35m\u001b[1m/workspace/wandb/run-20230911_111655-wqxhmzym\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Run \u001b[1m`wandb offline`\u001b[0m to turn off syncing.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Syncing run \u001b[33mflan_t5_large_squad_qg_lora_r32_al32\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: ⭐️ View project at \u001b[34m\u001b[4mhttps://wandb.ai/minseok0809/lmqg_qg_squad\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: 🚀 View run at \u001b[34m\u001b[4mhttps://wandb.ai/minseok0809/lmqg_qg_squad/runs/wqxhmzym\u001b[0m\n",
            "You are resizing the embedding layer without providing a `pad_to_multiple_of` parameter. This means that the new embeding dimension will be 32101. This might induce some performance reduction as *Tensor Cores* will not be available. For more details  about this, or help on choosing the correct value for resizing, refer to this guide: https://docs.nvidia.com/deeplearning/performance/dl-performance-matrix-multiplication/index.html#requirements-tc\n",
            "/opt/conda/lib/python3.8/site-packages/datasets/load.py:2072: FutureWarning: 'use_auth_token' was deprecated in favor of 'token' in version 2.14.0 and will be removed in 3.0.0.\n",
            "You can remove this warning by passing 'token=False' instead.\n",
            "  warnings.warn(\n",
            "\n",
            "\n",
            "Evaluation Time:  1:31:17\n",
            "Valid Bleu 1:  0.2352     Valid Bleu 2: 0.137\n",
            "Valid Bleu 3:  0.0912     Valid Bleu 4:  0.0648\n",
            "Test Bleu 1:  0.2355     Test Bleu 2:  0.1374\n",
            "Test Bleu 3:  0.0903     Test Bleu 4:  0.0631\n",
            "\n",
            "\n",
            "You are resizing the embedding layer without providing a `pad_to_multiple_of` parameter. This means that the new embeding dimension will be 32101. This might induce some performance reduction as *Tensor Cores* will not be available. For more details  about this, or help on choosing the correct value for resizing, refer to this guide: https://docs.nvidia.com/deeplearning/performance/dl-performance-matrix-multiplication/index.html#requirements-tc\n",
            "/opt/conda/lib/python3.8/site-packages/datasets/load.py:2072: FutureWarning: 'use_auth_token' was deprecated in favor of 'token' in version 2.14.0 and will be removed in 3.0.0.\n",
            "You can remove this warning by passing 'token=False' instead.\n",
            "  warnings.warn(\n",
            "\n",
            "\n",
            "Evaluation Time:  1:25:52\n",
            "Valid Bleu 1:  0.383     Valid Bleu 2: 0.2604\n",
            "Valid Bleu 3:  0.1937     Valid Bleu 4:  0.1492\n",
            "Test Bleu 1:  0.3736     Test Bleu 2:  0.2507\n",
            "Test Bleu 3:  0.1823     Test Bleu 4:  0.1374\n",
            "\n",
            "\n",
            "You are resizing the embedding layer without providing a `pad_to_multiple_of` parameter. This means that the new embeding dimension will be 32101. This might induce some performance reduction as *Tensor Cores* will not be available. For more details  about this, or help on choosing the correct value for resizing, refer to this guide: https://docs.nvidia.com/deeplearning/performance/dl-performance-matrix-multiplication/index.html#requirements-tc\n",
            "/opt/conda/lib/python3.8/site-packages/datasets/load.py:2072: FutureWarning: 'use_auth_token' was deprecated in favor of 'token' in version 2.14.0 and will be removed in 3.0.0.\n",
            "You can remove this warning by passing 'token=False' instead.\n",
            "  warnings.warn(\n",
            "\n",
            "\n",
            "Evaluation Time:  1:22:31\n",
            "Valid Bleu 1:  0.4599     Valid Bleu 2: 0.3264\n",
            "Valid Bleu 3:  0.2495     Valid Bleu 4:  0.1967\n",
            "Test Bleu 1:  0.461     Test Bleu 2:  0.3237\n",
            "Test Bleu 3:  0.2432     Test Bleu 4:  0.188\n",
            "\n",
            "\n",
            "You are resizing the embedding layer without providing a `pad_to_multiple_of` parameter. This means that the new embeding dimension will be 32101. This might induce some performance reduction as *Tensor Cores* will not be available. For more details  about this, or help on choosing the correct value for resizing, refer to this guide: https://docs.nvidia.com/deeplearning/performance/dl-performance-matrix-multiplication/index.html#requirements-tc\n",
            "/opt/conda/lib/python3.8/site-packages/datasets/load.py:2072: FutureWarning: 'use_auth_token' was deprecated in favor of 'token' in version 2.14.0 and will be removed in 3.0.0.\n",
            "You can remove this warning by passing 'token=False' instead.\n",
            "  warnings.warn(\n",
            "\n",
            "\n",
            "Evaluation Time:  1:17:03\n",
            "Valid Bleu 1:  0.5327     Valid Bleu 2: 0.3862\n",
            "Valid Bleu 3:  0.3006     Valid Bleu 4:  0.2407\n",
            "Test Bleu 1:  0.543     Test Bleu 2:  0.39\n",
            "Test Bleu 3:  0.2988     Test Bleu 4:  0.2349\n",
            "\n",
            "\n",
            "You are resizing the embedding layer without providing a `pad_to_multiple_of` parameter. This means that the new embeding dimension will be 32101. This might induce some performance reduction as *Tensor Cores* will not be available. For more details  about this, or help on choosing the correct value for resizing, refer to this guide: https://docs.nvidia.com/deeplearning/performance/dl-performance-matrix-multiplication/index.html#requirements-tc\n",
            "/opt/conda/lib/python3.8/site-packages/datasets/load.py:2072: FutureWarning: 'use_auth_token' was deprecated in favor of 'token' in version 2.14.0 and will be removed in 3.0.0.\n",
            "You can remove this warning by passing 'token=False' instead.\n",
            "  warnings.warn(\n",
            "\n",
            "\n",
            "Evaluation Time:  1:14:21\n",
            "Valid Bleu 1:  0.5628     Valid Bleu 2: 0.4124\n",
            "Valid Bleu 3:  0.3234     Valid Bleu 4:  0.2607\n",
            "Test Bleu 1:  0.5719     Test Bleu 2:  0.4153\n",
            "Test Bleu 3:  0.3203     Test Bleu 4:  0.2531\n",
            "\n",
            "\n",
            "You are resizing the embedding layer without providing a `pad_to_multiple_of` parameter. This means that the new embeding dimension will be 32101. This might induce some performance reduction as *Tensor Cores* will not be available. For more details  about this, or help on choosing the correct value for resizing, refer to this guide: https://docs.nvidia.com/deeplearning/performance/dl-performance-matrix-multiplication/index.html#requirements-tc\n",
            "/opt/conda/lib/python3.8/site-packages/datasets/load.py:2072: FutureWarning: 'use_auth_token' was deprecated in favor of 'token' in version 2.14.0 and will be removed in 3.0.0.\n",
            "You can remove this warning by passing 'token=False' instead.\n",
            "  warnings.warn(\n",
            "\n",
            "\n",
            "Evaluation Time:  1:12:58\n",
            "Valid Bleu 1:  0.577     Valid Bleu 2: 0.4252\n",
            "Valid Bleu 3:  0.3348     Valid Bleu 4:  0.2708\n",
            "Test Bleu 1:  0.5868     Test Bleu 2:  0.4274\n",
            "Test Bleu 3:  0.3307     Test Bleu 4:  0.262\n",
            "\n",
            "\n",
            "You are resizing the embedding layer without providing a `pad_to_multiple_of` parameter. This means that the new embeding dimension will be 32101. This might induce some performance reduction as *Tensor Cores* will not be available. For more details  about this, or help on choosing the correct value for resizing, refer to this guide: https://docs.nvidia.com/deeplearning/performance/dl-performance-matrix-multiplication/index.html#requirements-tc\n",
            "/opt/conda/lib/python3.8/site-packages/datasets/load.py:2072: FutureWarning: 'use_auth_token' was deprecated in favor of 'token' in version 2.14.0 and will be removed in 3.0.0.\n",
            "You can remove this warning by passing 'token=False' instead.\n",
            "  warnings.warn(\n",
            "\n",
            "\n",
            "Evaluation Time:  1:12:29\n",
            "Valid Bleu 1:  0.5813     Valid Bleu 2: 0.4292\n",
            "Valid Bleu 3:  0.3383     Valid Bleu 4:  0.2736\n",
            "Test Bleu 1:  0.5909     Test Bleu 2:  0.4315\n",
            "Test Bleu 3:  0.3345     Test Bleu 4:  0.2652\n",
            "\n",
            "\n",
            "You are resizing the embedding layer without providing a `pad_to_multiple_of` parameter. This means that the new embeding dimension will be 32101. This might induce some performance reduction as *Tensor Cores* will not be available. For more details  about this, or help on choosing the correct value for resizing, refer to this guide: https://docs.nvidia.com/deeplearning/performance/dl-performance-matrix-multiplication/index.html#requirements-tc\n",
            "/opt/conda/lib/python3.8/site-packages/datasets/load.py:2072: FutureWarning: 'use_auth_token' was deprecated in favor of 'token' in version 2.14.0 and will be removed in 3.0.0.\n",
            "You can remove this warning by passing 'token=False' instead.\n",
            "  warnings.warn(\n",
            "\n",
            "\n",
            "Evaluation Time:  1:12:34\n",
            "Valid Bleu 1:  0.581     Valid Bleu 2: 0.4302\n",
            "Valid Bleu 3:  0.34     Valid Bleu 4:  0.276\n",
            "Test Bleu 1:  0.5928     Test Bleu 2:  0.4327\n",
            "Test Bleu 3:  0.3353     Test Bleu 4:  0.266\n",
            "\n",
            "\n",
            "You are resizing the embedding layer without providing a `pad_to_multiple_of` parameter. This means that the new embeding dimension will be 32101. This might induce some performance reduction as *Tensor Cores* will not be available. For more details  about this, or help on choosing the correct value for resizing, refer to this guide: https://docs.nvidia.com/deeplearning/performance/dl-performance-matrix-multiplication/index.html#requirements-tc\n",
            "/opt/conda/lib/python3.8/site-packages/datasets/load.py:2072: FutureWarning: 'use_auth_token' was deprecated in favor of 'token' in version 2.14.0 and will be removed in 3.0.0.\n",
            "You can remove this warning by passing 'token=False' instead.\n",
            "  warnings.warn(\n",
            "\n",
            "\n",
            "Evaluation Time:  1:13:05\n",
            "Valid Bleu 1:  0.5779     Valid Bleu 2: 0.4275\n",
            "Valid Bleu 3:  0.3373     Valid Bleu 4:  0.2732\n",
            "Test Bleu 1:  0.5926     Test Bleu 2:  0.4336\n",
            "Test Bleu 3:  0.3365     Test Bleu 4:  0.267\n",
            "\n",
            "\n",
            "You are resizing the embedding layer without providing a `pad_to_multiple_of` parameter. This means that the new embeding dimension will be 32101. This might induce some performance reduction as *Tensor Cores* will not be available. For more details  about this, or help on choosing the correct value for resizing, refer to this guide: https://docs.nvidia.com/deeplearning/performance/dl-performance-matrix-multiplication/index.html#requirements-tc\n",
            "/opt/conda/lib/python3.8/site-packages/datasets/load.py:2072: FutureWarning: 'use_auth_token' was deprecated in favor of 'token' in version 2.14.0 and will be removed in 3.0.0.\n",
            "You can remove this warning by passing 'token=False' instead.\n",
            "  warnings.warn(\n",
            "\n",
            "\n",
            "Evaluation Time:  1:12:24\n",
            "Valid Bleu 1:  0.5837     Valid Bleu 2: 0.4327\n",
            "Valid Bleu 3:  0.3418     Valid Bleu 4:  0.2772\n",
            "Test Bleu 1:  0.5961     Test Bleu 2:  0.4374\n",
            "Test Bleu 3:  0.3401     Test Bleu 4:  0.2702\n",
            "\n",
            "\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Waiting for W&B process to finish... \u001b[32m(success).\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Run history:\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:  test_bleu_1 ▁▄▅▇██████\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:  test_bleu_2 ▁▄▅▇▇█████\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:  test_bleu_3 ▁▄▅▇▇█████\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:  test_bleu_4 ▁▄▅▇▇█████\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: valid_bleu_1 ▁▄▆▇██████\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: valid_bleu_2 ▁▄▅▇██████\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: valid_bleu_3 ▁▄▅▇▇█████\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: valid_bleu_4 ▁▄▅▇▇█████\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Run summary:\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:  test_bleu_1 0.59605\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:  test_bleu_2 0.43735\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:  test_bleu_3 0.34005\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:  test_bleu_4 0.27017\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: valid_bleu_1 0.58373\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: valid_bleu_2 0.43273\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: valid_bleu_3 0.3418\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: valid_bleu_4 0.27719\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: 🚀 View run \u001b[33mflan_t5_large_squad_qg_lora_r32_al32\u001b[0m at: \u001b[34m\u001b[4mhttps://wandb.ai/minseok0809/lmqg_qg_squad/runs/wqxhmzym\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Find logs at: \u001b[35m\u001b[1m./wandb/run-20230911_111655-wqxhmzym/logs\u001b[0m\n"
          ]
        }
      ],
      "source": [
        "!python -m lm-question-generation.lmqg.grid_searcher_flan_t5_large_squad_qg_lora_r32_al32_evaluation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mminseok0809\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: wandb version 0.15.10 is available!  To upgrade, please run:\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:  $ pip install wandb --upgrade\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.15.9\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Run data is saved locally in \u001b[35m\u001b[1m/workspace/wandb/run-20230912_005903-306cxiqf\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Run \u001b[1m`wandb offline`\u001b[0m to turn off syncing.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Syncing run \u001b[33mflan_t5_large_squad_qg_lora_r64_al32\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: ⭐️ View project at \u001b[34m\u001b[4mhttps://wandb.ai/minseok0809/lmqg_qg_squad\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: 🚀 View run at \u001b[34m\u001b[4mhttps://wandb.ai/minseok0809/lmqg_qg_squad/runs/306cxiqf\u001b[0m\n",
            "/opt/conda/lib/python3.8/site-packages/transformers/models/auto/tokenization_auto.py:631: FutureWarning: The `use_auth_token` argument is deprecated and will be removed in v5 of Transformers.\n",
            "  warnings.warn(\n",
            "/opt/conda/lib/python3.8/site-packages/transformers/models/auto/configuration_auto.py:995: FutureWarning: The `use_auth_token` argument is deprecated and will be removed in v5 of Transformers.\n",
            "  warnings.warn(\n",
            "/opt/conda/lib/python3.8/site-packages/transformers/modeling_utils.py:2310: FutureWarning: The `use_auth_token` argument is deprecated and will be removed in v5 of Transformers.\n",
            "  warnings.warn(\n",
            "/opt/conda/lib/python3.8/site-packages/transformers/utils/hub.py:373: FutureWarning: The `use_auth_token` argument is deprecated and will be removed in v5 of Transformers.\n",
            "  warnings.warn(\n",
            "You are resizing the embedding layer without providing a `pad_to_multiple_of` parameter. This means that the new embeding dimension will be 32101. This might induce some performance reduction as *Tensor Cores* will not be available. For more details  about this, or help on choosing the correct value for resizing, refer to this guide: https://docs.nvidia.com/deeplearning/performance/dl-performance-matrix-multiplication/index.html#requirements-tc\n",
            "\n",
            "\n",
            "trainable model parameters: 18874368\n",
            "all model parameters: 801969152\n",
            "percentage of trainable model parameters: 2.35% \n",
            "\n",
            "/opt/conda/lib/python3.8/site-packages/datasets/load.py:2072: FutureWarning: 'use_auth_token' was deprecated in favor of 'token' in version 2.14.0 and will be removed in 3.0.0.\n",
            "You can remove this warning by passing 'token=False' instead.\n",
            "  warnings.warn(\n",
            "\n",
            "\n",
            "Epoch 1: 100%|██████████████████████████| 18792/18792 [1:07:34<00:00,  4.64it/s]\n",
            "Loss :   8.0436\n",
            "\n",
            "\n",
            "Epoch 2: 100%|██████████████████████████| 18792/18792 [1:07:41<00:00,  4.63it/s]\n",
            "Loss :   0.8071\n",
            "\n",
            "\n",
            "Epoch 3: 100%|██████████████████████████| 18792/18792 [1:07:36<00:00,  4.63it/s]\n",
            "Loss :   0.7627\n",
            "\n",
            "\n",
            "Epoch 4: 100%|██████████████████████████| 18792/18792 [1:07:38<00:00,  4.63it/s]\n",
            "Loss :   0.7231\n",
            "\n",
            "\n",
            "Epoch 5: 100%|██████████████████████████| 18792/18792 [1:07:43<00:00,  4.63it/s]\n",
            "Loss :   0.7058\n",
            "\n",
            "\n",
            "Epoch 6: 100%|██████████████████████████| 18792/18792 [1:07:37<00:00,  4.63it/s]\n",
            "Loss :   0.6932\n",
            "\n",
            "\n",
            "Epoch 7: 100%|██████████████████████████| 18792/18792 [1:07:38<00:00,  4.63it/s]\n",
            "Loss :   0.6774\n",
            "\n",
            "\n",
            "Epoch 8: 100%|██████████████████████████| 18792/18792 [1:07:35<00:00,  4.63it/s]\n",
            "Loss :   0.6588\n",
            "\n",
            "\n",
            "Epoch 9: 100%|██████████████████████████| 18792/18792 [1:07:36<00:00,  4.63it/s]\n",
            "Loss :   0.6464\n",
            "\n",
            "\n",
            "Epoch 10: 100%|█████████████████████████| 18792/18792 [1:07:41<00:00,  4.63it/s]\n",
            "Loss :   0.6394\n",
            "\n",
            "\n",
            "Epoch 11: 100%|█████████████████████████| 18792/18792 [1:07:42<00:00,  4.63it/s]\n",
            "Loss :   0.6336\n",
            "\n",
            "\n",
            "Epoch 12: 100%|█████████████████████████| 18792/18792 [1:07:38<00:00,  4.63it/s]\n",
            "Loss :   0.6273\n",
            "\n",
            "\n",
            "Epoch 13: 100%|█████████████████████████| 18792/18792 [1:07:35<00:00,  4.63it/s]\n",
            "Loss :   0.6215\n",
            "\n",
            "\n",
            "Epoch 14: 100%|█████████████████████████| 18792/18792 [1:07:45<00:00,  4.62it/s]\n",
            "Loss :   0.6171\n",
            "\n",
            "\n",
            "Epoch 15: 100%|█████████████████████████| 18792/18792 [1:07:43<00:00,  4.62it/s]\n",
            "Loss :   0.6121\n",
            "\n",
            "\n",
            "Epoch 16: 100%|█████████████████████████| 18792/18792 [1:07:37<00:00,  4.63it/s]\n",
            "Loss :   0.6086\n",
            "\n",
            "\n",
            "Epoch 17: 100%|█████████████████████████| 18792/18792 [1:07:46<00:00,  4.62it/s]\n",
            "Loss :   0.6047\n",
            "\n",
            "\n",
            "Epoch 18: 100%|█████████████████████████| 18792/18792 [1:07:40<00:00,  4.63it/s]\n",
            "Loss :   0.6009\n",
            "\n",
            "\n",
            "Epoch 19: 100%|█████████████████████████| 18792/18792 [1:07:29<00:00,  4.64it/s]\n",
            "Loss :   0.5982\n",
            "\n",
            "\n",
            "Epoch 20: 100%|█████████████████████████| 18792/18792 [1:07:32<00:00,  4.64it/s]\n",
            "Loss :   0.5949\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Waiting for W&B process to finish... \u001b[32m(success).\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: | 0.006 MB of 0.062 MB uploaded (0.000 MB deduped)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Run history:\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: loss █▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Run summary:\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: loss 0.5949\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: 🚀 View run \u001b[33mflan_t5_large_squad_qg_lora_r64_al32\u001b[0m at: \u001b[34m\u001b[4mhttps://wandb.ai/minseok0809/lmqg_qg_squad/runs/306cxiqf\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Find logs at: \u001b[35m\u001b[1m./wandb/run-20230912_005903-306cxiqf/logs\u001b[0m\n"
          ]
        }
      ],
      "source": [
        "!python -m lm-question-generation.lmqg.grid_searcher_flan_t5_large_squad_qg_lora_r64_al32_training"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mminseok0809\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: wandb version 0.15.10 is available!  To upgrade, please run:\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:  $ pip install wandb --upgrade\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.15.9\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Run data is saved locally in \u001b[35m\u001b[1m/workspace/wandb/run-20230912_233241-ke2llayz\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Run \u001b[1m`wandb offline`\u001b[0m to turn off syncing.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Syncing run \u001b[33mflan_t5_large_squad_qg_lora_r64_al32\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: ⭐️ View project at \u001b[34m\u001b[4mhttps://wandb.ai/minseok0809/lmqg_qg_squad\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: 🚀 View run at \u001b[34m\u001b[4mhttps://wandb.ai/minseok0809/lmqg_qg_squad/runs/ke2llayz\u001b[0m\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "You are resizing the embedding layer without providing a `pad_to_multiple_of` parameter. This means that the new embeding dimension will be 32101. This might induce some performance reduction as *Tensor Cores* will not be available. For more details  about this, or help on choosing the correct value for resizing, refer to this guide: https://docs.nvidia.com/deeplearning/performance/dl-performance-matrix-multiplication/index.html#requirements-tc\n",
            "/opt/conda/lib/python3.8/site-packages/datasets/load.py:2072: FutureWarning: 'use_auth_token' was deprecated in favor of 'token' in version 2.14.0 and will be removed in 3.0.0.\n",
            "You can remove this warning by passing 'token=False' instead.\n",
            "  warnings.warn(\n",
            "\n",
            "\n",
            "Evaluation Time:  1:31:20\n",
            "Valid Bleu 1:  0.2186     Valid Bleu 2: 0.1261\n",
            "Valid Bleu 3:  0.0831     Valid Bleu 4:  0.0584\n",
            "Test Bleu 1:  0.2213     Test Bleu 2:  0.1272\n",
            "Test Bleu 3:  0.0824     Test Bleu 4:  0.0569\n",
            "\n",
            "\n",
            "You are resizing the embedding layer without providing a `pad_to_multiple_of` parameter. This means that the new embeding dimension will be 32101. This might induce some performance reduction as *Tensor Cores* will not be available. For more details  about this, or help on choosing the correct value for resizing, refer to this guide: https://docs.nvidia.com/deeplearning/performance/dl-performance-matrix-multiplication/index.html#requirements-tc\n",
            "/opt/conda/lib/python3.8/site-packages/datasets/load.py:2072: FutureWarning: 'use_auth_token' was deprecated in favor of 'token' in version 2.14.0 and will be removed in 3.0.0.\n",
            "You can remove this warning by passing 'token=False' instead.\n",
            "  warnings.warn(\n",
            "\n",
            "\n",
            "Evaluation Time:  1:29:23\n",
            "Valid Bleu 1:  0.2907     Valid Bleu 2: 0.1862\n",
            "Valid Bleu 3:  0.1322     Valid Bleu 4:  0.0982\n",
            "Test Bleu 1:  0.285     Test Bleu 2:  0.1788\n",
            "Test Bleu 3:  0.1234     Test Bleu 4:  0.0892\n",
            "\n",
            "\n",
            "You are resizing the embedding layer without providing a `pad_to_multiple_of` parameter. This means that the new embeding dimension will be 32101. This might induce some performance reduction as *Tensor Cores* will not be available. For more details  about this, or help on choosing the correct value for resizing, refer to this guide: https://docs.nvidia.com/deeplearning/performance/dl-performance-matrix-multiplication/index.html#requirements-tc\n",
            "/opt/conda/lib/python3.8/site-packages/datasets/load.py:2072: FutureWarning: 'use_auth_token' was deprecated in favor of 'token' in version 2.14.0 and will be removed in 3.0.0.\n",
            "You can remove this warning by passing 'token=False' instead.\n",
            "  warnings.warn(\n",
            "\n",
            "\n",
            "Evaluation Time:  1:25:40\n",
            "Valid Bleu 1:  0.3724     Valid Bleu 2: 0.2517\n",
            "Valid Bleu 3:  0.1857     Valid Bleu 4:  0.1423\n",
            "Test Bleu 1:  0.3579     Test Bleu 2:  0.2386\n",
            "Test Bleu 3:  0.1724     Test Bleu 4:  0.1295\n",
            "\n",
            "\n",
            "You are resizing the embedding layer without providing a `pad_to_multiple_of` parameter. This means that the new embeding dimension will be 32101. This might induce some performance reduction as *Tensor Cores* will not be available. For more details  about this, or help on choosing the correct value for resizing, refer to this guide: https://docs.nvidia.com/deeplearning/performance/dl-performance-matrix-multiplication/index.html#requirements-tc\n",
            "/opt/conda/lib/python3.8/site-packages/datasets/load.py:2072: FutureWarning: 'use_auth_token' was deprecated in favor of 'token' in version 2.14.0 and will be removed in 3.0.0.\n",
            "You can remove this warning by passing 'token=False' instead.\n",
            "  warnings.warn(\n",
            "\n",
            "\n",
            "Evaluation Time:  1:20:36\n",
            "Valid Bleu 1:  0.4667     Valid Bleu 2: 0.3307\n",
            "Valid Bleu 3:  0.2528     Valid Bleu 4:  0.1994\n",
            "Test Bleu 1:  0.4594     Test Bleu 2:  0.3213\n",
            "Test Bleu 3:  0.2406     Test Bleu 4:  0.1857\n",
            "\n",
            "\n",
            "You are resizing the embedding layer without providing a `pad_to_multiple_of` parameter. This means that the new embeding dimension will be 32101. This might induce some performance reduction as *Tensor Cores* will not be available. For more details  about this, or help on choosing the correct value for resizing, refer to this guide: https://docs.nvidia.com/deeplearning/performance/dl-performance-matrix-multiplication/index.html#requirements-tc\n",
            "/opt/conda/lib/python3.8/site-packages/datasets/load.py:2072: FutureWarning: 'use_auth_token' was deprecated in favor of 'token' in version 2.14.0 and will be removed in 3.0.0.\n",
            "You can remove this warning by passing 'token=False' instead.\n",
            "  warnings.warn(\n",
            "\n",
            "\n",
            "Evaluation Time:  1:20:22\n",
            "Valid Bleu 1:  0.4768     Valid Bleu 2: 0.34\n",
            "Valid Bleu 3:  0.2609     Valid Bleu 4:  0.2064\n",
            "Test Bleu 1:  0.4793     Test Bleu 2:  0.3388\n",
            "Test Bleu 3:  0.2556     Test Bleu 4:  0.1983\n",
            "\n",
            "\n",
            "You are resizing the embedding layer without providing a `pad_to_multiple_of` parameter. This means that the new embeding dimension will be 32101. This might induce some performance reduction as *Tensor Cores* will not be available. For more details  about this, or help on choosing the correct value for resizing, refer to this guide: https://docs.nvidia.com/deeplearning/performance/dl-performance-matrix-multiplication/index.html#requirements-tc\n",
            "/opt/conda/lib/python3.8/site-packages/datasets/load.py:2072: FutureWarning: 'use_auth_token' was deprecated in favor of 'token' in version 2.14.0 and will be removed in 3.0.0.\n",
            "You can remove this warning by passing 'token=False' instead.\n",
            "  warnings.warn(\n",
            "\n",
            "\n",
            "Evaluation Time:  1:17:55\n",
            "Valid Bleu 1:  0.5115     Valid Bleu 2: 0.3691\n",
            "Valid Bleu 3:  0.2861     Valid Bleu 4:  0.2285\n",
            "Test Bleu 1:  0.5187     Test Bleu 2:  0.37\n",
            "Test Bleu 3:  0.2819     Test Bleu 4:  0.2204\n",
            "\n",
            "\n",
            "You are resizing the embedding layer without providing a `pad_to_multiple_of` parameter. This means that the new embeding dimension will be 32101. This might induce some performance reduction as *Tensor Cores* will not be available. For more details  about this, or help on choosing the correct value for resizing, refer to this guide: https://docs.nvidia.com/deeplearning/performance/dl-performance-matrix-multiplication/index.html#requirements-tc\n",
            "/opt/conda/lib/python3.8/site-packages/datasets/load.py:2072: FutureWarning: 'use_auth_token' was deprecated in favor of 'token' in version 2.14.0 and will be removed in 3.0.0.\n",
            "You can remove this warning by passing 'token=False' instead.\n",
            "  warnings.warn(\n",
            "\n",
            "\n",
            "Evaluation Time:  1:14:40\n",
            "Valid Bleu 1:  0.5464     Valid Bleu 2: 0.3986\n",
            "Valid Bleu 3:  0.3111     Valid Bleu 4:  0.2499\n",
            "Test Bleu 1:  0.5559     Test Bleu 2:  0.4014\n",
            "Test Bleu 3:  0.3083     Test Bleu 4:  0.2427\n",
            "\n",
            "\n",
            "You are resizing the embedding layer without providing a `pad_to_multiple_of` parameter. This means that the new embeding dimension will be 32101. This might induce some performance reduction as *Tensor Cores* will not be available. For more details  about this, or help on choosing the correct value for resizing, refer to this guide: https://docs.nvidia.com/deeplearning/performance/dl-performance-matrix-multiplication/index.html#requirements-tc\n",
            "/opt/conda/lib/python3.8/site-packages/datasets/load.py:2072: FutureWarning: 'use_auth_token' was deprecated in favor of 'token' in version 2.14.0 and will be removed in 3.0.0.\n",
            "You can remove this warning by passing 'token=False' instead.\n",
            "  warnings.warn(\n",
            "\n",
            "\n",
            "Evaluation Time:  1:12:30\n",
            "Valid Bleu 1:  0.5661     Valid Bleu 2: 0.4159\n",
            "Valid Bleu 3:  0.3263     Valid Bleu 4:  0.2632\n",
            "Test Bleu 1:  0.5772     Test Bleu 2:  0.4191\n",
            "Test Bleu 3:  0.3234     Test Bleu 4:  0.2555\n",
            "\n",
            "\n",
            "You are resizing the embedding layer without providing a `pad_to_multiple_of` parameter. This means that the new embeding dimension will be 32101. This might induce some performance reduction as *Tensor Cores* will not be available. For more details  about this, or help on choosing the correct value for resizing, refer to this guide: https://docs.nvidia.com/deeplearning/performance/dl-performance-matrix-multiplication/index.html#requirements-tc\n",
            "/opt/conda/lib/python3.8/site-packages/datasets/load.py:2072: FutureWarning: 'use_auth_token' was deprecated in favor of 'token' in version 2.14.0 and will be removed in 3.0.0.\n",
            "You can remove this warning by passing 'token=False' instead.\n",
            "  warnings.warn(\n",
            "\n",
            "\n",
            "Evaluation Time:  1:11:11\n",
            "Valid Bleu 1:  0.5751     Valid Bleu 2: 0.424\n",
            "Valid Bleu 3:  0.3337     Valid Bleu 4:  0.2697\n",
            "Test Bleu 1:  0.5886     Test Bleu 2:  0.4287\n",
            "Test Bleu 3:  0.3315     Test Bleu 4:  0.2623\n",
            "\n",
            "\n",
            "You are resizing the embedding layer without providing a `pad_to_multiple_of` parameter. This means that the new embeding dimension will be 32101. This might induce some performance reduction as *Tensor Cores* will not be available. For more details  about this, or help on choosing the correct value for resizing, refer to this guide: https://docs.nvidia.com/deeplearning/performance/dl-performance-matrix-multiplication/index.html#requirements-tc\n",
            "/opt/conda/lib/python3.8/site-packages/datasets/load.py:2072: FutureWarning: 'use_auth_token' was deprecated in favor of 'token' in version 2.14.0 and will be removed in 3.0.0.\n",
            "You can remove this warning by passing 'token=False' instead.\n",
            "  warnings.warn(\n",
            "\n",
            "\n",
            "Evaluation Time:  1:11:16\n",
            "Valid Bleu 1:  0.5753     Valid Bleu 2: 0.4246\n",
            "Valid Bleu 3:  0.3346     Valid Bleu 4:  0.2708\n",
            "Test Bleu 1:  0.5902     Test Bleu 2:  0.4311\n",
            "Test Bleu 3:  0.3343     Test Bleu 4:  0.265\n",
            "\n",
            "\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Waiting for W&B process to finish... \u001b[32m(success).\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Run history:\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:  test_bleu_1 ▁▂▄▆▆▇▇███\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:  test_bleu_2 ▁▂▄▅▆▇▇███\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:  test_bleu_3 ▁▂▄▅▆▇▇███\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:  test_bleu_4 ▁▂▃▅▆▆▇███\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: valid_bleu_1 ▁▂▄▆▆▇▇███\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: valid_bleu_2 ▁▂▄▆▆▇▇███\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: valid_bleu_3 ▁▂▄▆▆▇▇███\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: valid_bleu_4 ▁▂▄▆▆▇▇███\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Run summary:\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:  test_bleu_1 0.59019\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:  test_bleu_2 0.43115\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:  test_bleu_3 0.33431\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:  test_bleu_4 0.26499\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: valid_bleu_1 0.57528\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: valid_bleu_2 0.42463\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: valid_bleu_3 0.33456\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: valid_bleu_4 0.27078\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: 🚀 View run \u001b[33mflan_t5_large_squad_qg_lora_r64_al32\u001b[0m at: \u001b[34m\u001b[4mhttps://wandb.ai/minseok0809/lmqg_qg_squad/runs/ke2llayz\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Find logs at: \u001b[35m\u001b[1m./wandb/run-20230912_233241-ke2llayz/logs\u001b[0m\n"
          ]
        }
      ],
      "source": [
        "!python -m lm-question-generation.lmqg.grid_searcher_flan_t5_large_squad_qg_lora_r64_al32_evaluation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "!python -m lm-question-generation.lmqg.grid_searcher_flan_t5_large_squad_qg_lora_r128_al32_training"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "!python -m lm-question-generation.lmqg.grid_searcher_flan_t5_large_squad_qg_lora_r128_al32_evaluation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "wandb.finish()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Flan T5 XL Model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Original Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "!python -m lm-question-generation.lmqg.grid_searcher_flan_t5_xl_squad_qg"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "wandb.finish()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Lora Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "!python -m lm-question-generation.lmqg.grid_searcher_flan_t5_xl_squad_qg_lora_r1_al32_training "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "!python -m lm-question-generation.lmqg.grid_searcher_flan_t5_xl_squad_qg_lora_r1_al32_evaluation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "!python -m lm-question-generation.lmqg.grid_searcher_flan_t5_xl_squad_qg_lora_r2_al32_training "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "!python -m lm-question-generation.lmqg.grid_searcher_flan_t5_xl_squad_qg_lora_r2_al32_evaluation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "!python -m lm-question-generation.lmqg.grid_searcher_flan_t5_xl_squad_qg_lora_r4_al32_training "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "!python -m lm-question-generation.lmqg.grid_searcher_flan_t5_xl_squad_qg_lora_r4_al32_evaluation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "!python -m lm-question-generation.lmqg.grid_searcher_flan_t5_xl_squad_qg_lora_r8_al32_training "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "!python -m lm-question-generation.lmqg.grid_searcher_flan_t5_xl_squad_qg_lora_r8_al32_evaluation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "!python -m lm-question-generation.lmqg.grid_searcher_flan_t5_xl_squad_qg_lora_r16_al32_training "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "!python -m lm-question-generation.lmqg.grid_searcher_flan_t5_xl_squad_qg_lora_r16_al32_evaluation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "!python -m lm-question-generation.lmqg.grid_searcher_flan_t5_xl_squad_qg_lora_r32_al32_training "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "!python -m lm-question-generation.lmqg.grid_searcher_flan_t5_xl_squad_qg_lora_r32_al32_evaluation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "!python -m lm-question-generation.lmqg.grid_searcher_flan_t5_xl_squad_qg_lora_r64_al32_training "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "!python -m lm-question-generation.lmqg.grid_searcher_flan_t5_xl_squad_qg_lora_r64_al32_evaluation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mminseok0809\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: wandb version 0.15.10 is available!  To upgrade, please run:\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:  $ pip install wandb --upgrade\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.15.9\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Run data is saved locally in \u001b[35m\u001b[1m/workspace/wandb/run-20230907_041656-9bz9oo2z\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Run \u001b[1m`wandb offline`\u001b[0m to turn off syncing.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Syncing run \u001b[33mflan_t5_xl_squad_qg_lora_r128_al32\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: ⭐️ View project at \u001b[34m\u001b[4mhttps://wandb.ai/minseok0809/lmqg_qg_squad\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: 🚀 View run at \u001b[34m\u001b[4mhttps://wandb.ai/minseok0809/lmqg_qg_squad/runs/9bz9oo2z\u001b[0m\n",
            "/opt/conda/lib/python3.8/site-packages/transformers/models/auto/tokenization_auto.py:631: FutureWarning: The `use_auth_token` argument is deprecated and will be removed in v5 of Transformers.\n",
            "  warnings.warn(\n",
            "/opt/conda/lib/python3.8/site-packages/transformers/models/auto/configuration_auto.py:995: FutureWarning: The `use_auth_token` argument is deprecated and will be removed in v5 of Transformers.\n",
            "  warnings.warn(\n",
            "/opt/conda/lib/python3.8/site-packages/transformers/modeling_utils.py:2310: FutureWarning: The `use_auth_token` argument is deprecated and will be removed in v5 of Transformers.\n",
            "  warnings.warn(\n",
            "Loading checkpoint shards: 100%|██████████████████| 2/2 [00:04<00:00,  2.08s/it]\n",
            "/opt/conda/lib/python3.8/site-packages/transformers/utils/hub.py:373: FutureWarning: The `use_auth_token` argument is deprecated and will be removed in v5 of Transformers.\n",
            "  warnings.warn(\n",
            "You are resizing the embedding layer without providing a `pad_to_multiple_of` parameter. This means that the new embeding dimension will be 32101. This might induce some performance reduction as *Tensor Cores* will not be available. For more details  about this, or help on choosing the correct value for resizing, refer to this guide: https://docs.nvidia.com/deeplearning/performance/dl-performance-matrix-multiplication/index.html#requirements-tc\n",
            "\n",
            "\n",
            "trainable model parameters: 75497472\n",
            "all model parameters: 2925144064\n",
            "percentage of trainable model parameters: 2.58% \n",
            "\n",
            "/opt/conda/lib/python3.8/site-packages/datasets/load.py:2072: FutureWarning: 'use_auth_token' was deprecated in favor of 'token' in version 2.14.0 and will be removed in 3.0.0.\n",
            "You can remove this warning by passing 'token=False' instead.\n",
            "  warnings.warn(\n",
            "\n",
            "\n",
            "Epoch 1: 100%|██████████████████████████| 37585/37585 [2:43:43<00:00,  3.83it/s]\n",
            "Loss :   2.2544\n",
            "\n",
            "\n",
            "Epoch 2: 100%|██████████████████████████| 37585/37585 [2:44:05<00:00,  3.82it/s]\n",
            "Loss :   0.5765\n",
            "\n",
            "\n",
            "Epoch 3: 100%|██████████████████████████| 37585/37585 [2:44:12<00:00,  3.81it/s]\n",
            "Loss :   0.5617\n",
            "\n",
            "\n",
            "Epoch 4: 100%|██████████████████████████| 37585/37585 [2:44:10<00:00,  3.82it/s]\n",
            "Loss :   0.5537\n",
            "\n",
            "\n",
            "Epoch 5: 100%|██████████████████████████| 37585/37585 [2:44:14<00:00,  3.81it/s]\n",
            "Loss :   0.5463\n",
            "\n",
            "\n",
            "Epoch 6: 100%|██████████████████████████| 37585/37585 [2:44:40<00:00,  3.80it/s]\n",
            "Loss :   0.5404\n",
            "\n",
            "\n",
            "Epoch 7: 100%|██████████████████████████| 37585/37585 [2:44:53<00:00,  3.80it/s]\n",
            "Loss :   0.5344\n",
            "\n",
            "\n",
            "Epoch 8: 100%|██████████████████████████| 37585/37585 [2:44:07<00:00,  3.82it/s]\n",
            "Loss :   0.5291\n",
            "\n",
            "\n",
            "Epoch 9: 100%|██████████████████████████| 37585/37585 [2:44:24<00:00,  3.81it/s]\n",
            "Loss :   0.5241\n",
            "\n",
            "\n",
            "Epoch 10: 100%|█████████████████████████| 37585/37585 [2:44:37<00:00,  3.81it/s]\n",
            "Loss :   0.5199\n",
            "\n",
            "\n",
            "Epoch 11: 100%|█████████████████████████| 37585/37585 [2:44:36<00:00,  3.81it/s]\n",
            "Loss :   0.5158\n",
            "\n",
            "\n",
            "Epoch 12: 100%|█████████████████████████| 37585/37585 [2:44:44<00:00,  3.80it/s]\n",
            "Loss :   0.5116\n",
            "\n",
            "\n",
            "Epoch 13: 100%|█████████████████████████| 37585/37585 [2:44:28<00:00,  3.81it/s]\n",
            "Loss :   0.5078\n",
            "\n",
            "\n",
            "Epoch 14: 100%|█████████████████████████| 37585/37585 [2:44:30<00:00,  3.81it/s]\n",
            "Loss :   0.5041\n",
            "\n",
            "\n",
            "Epoch 15: 100%|█████████████████████████| 37585/37585 [2:44:21<00:00,  3.81it/s]\n",
            "Loss :   0.5002\n",
            "\n",
            "\n",
            "Epoch 16: 100%|█████████████████████████| 37585/37585 [2:44:31<00:00,  3.81it/s]\n",
            "Loss :   0.497\n",
            "\n",
            "\n",
            "Epoch 17: 100%|█████████████████████████| 37585/37585 [2:44:30<00:00,  3.81it/s]\n",
            "Loss :   0.4941\n",
            "\n",
            "\n",
            "Epoch 18: 100%|█████████████████████████| 37585/37585 [2:44:31<00:00,  3.81it/s]\n",
            "Loss :   0.4907\n",
            "\n",
            "\n",
            "Epoch 19: 100%|█████████████████████████| 37585/37585 [2:44:41<00:00,  3.80it/s]\n",
            "Loss :   0.4872\n",
            "\n",
            "\n",
            "Epoch 20: 100%|█████████████████████████| 37585/37585 [2:44:33<00:00,  3.81it/s]\n",
            "Loss :   0.4839\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Waiting for W&B process to finish... \u001b[32m(success).\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Run history:\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: loss █▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Run summary:\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: loss 0.48395\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: 🚀 View run \u001b[33mflan_t5_xl_squad_qg_lora_r128_al32\u001b[0m at: \u001b[34m\u001b[4mhttps://wandb.ai/minseok0809/lmqg_qg_squad/runs/9bz9oo2z\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Find logs at: \u001b[35m\u001b[1m./wandb/run-20230907_041656-9bz9oo2z/logs\u001b[0m\n"
          ]
        }
      ],
      "source": [
        "!python -m lm-question-generation.lmqg.grid_searcher_flan_t5_xl_squad_qg_lora_r128_al32_training "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mminseok0809\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: wandb version 0.15.10 is available!  To upgrade, please run:\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:  $ pip install wandb --upgrade\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.15.9\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Run data is saved locally in \u001b[35m\u001b[1m/workspace/wandb/run-20230909_110654-gti4mgrf\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Run \u001b[1m`wandb offline`\u001b[0m to turn off syncing.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Syncing run \u001b[33mflan_t5_xl_squad_qg_lora_r128_al32\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: ⭐️ View project at \u001b[34m\u001b[4mhttps://wandb.ai/minseok0809/lmqg_qg_squad\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: 🚀 View run at \u001b[34m\u001b[4mhttps://wandb.ai/minseok0809/lmqg_qg_squad/runs/gti4mgrf\u001b[0m\n",
            "Loading checkpoint shards: 100%|██████████████████| 2/2 [00:04<00:00,  2.04s/it]\n",
            "You are resizing the embedding layer without providing a `pad_to_multiple_of` parameter. This means that the new embeding dimension will be 32101. This might induce some performance reduction as *Tensor Cores* will not be available. For more details  about this, or help on choosing the correct value for resizing, refer to this guide: https://docs.nvidia.com/deeplearning/performance/dl-performance-matrix-multiplication/index.html#requirements-tc\n",
            "/opt/conda/lib/python3.8/site-packages/datasets/load.py:2072: FutureWarning: 'use_auth_token' was deprecated in favor of 'token' in version 2.14.0 and will be removed in 3.0.0.\n",
            "You can remove this warning by passing 'token=False' instead.\n",
            "  warnings.warn(\n",
            "\n",
            "\n",
            "Evaluation Time:  3:12:52\n",
            "Valid Bleu 1:  0.2854     Valid Bleu 2: 0.1887\n",
            "Valid Bleu 3:  0.1356     Valid Bleu 4:  0.1014\n",
            "Test Bleu 1:  0.2935     Test Bleu 2:  0.1923\n",
            "Test Bleu 3:  0.1359     Test Bleu 4:  0.0996\n",
            "\n",
            "\n",
            "Loading checkpoint shards: 100%|██████████████████| 2/2 [00:04<00:00,  2.04s/it]\n",
            "You are resizing the embedding layer without providing a `pad_to_multiple_of` parameter. This means that the new embeding dimension will be 32101. This might induce some performance reduction as *Tensor Cores* will not be available. For more details  about this, or help on choosing the correct value for resizing, refer to this guide: https://docs.nvidia.com/deeplearning/performance/dl-performance-matrix-multiplication/index.html#requirements-tc\n",
            "/opt/conda/lib/python3.8/site-packages/datasets/load.py:2072: FutureWarning: 'use_auth_token' was deprecated in favor of 'token' in version 2.14.0 and will be removed in 3.0.0.\n",
            "You can remove this warning by passing 'token=False' instead.\n",
            "  warnings.warn(\n",
            "\n",
            "\n",
            "Evaluation Time:  2:51:01\n",
            "Valid Bleu 1:  0.4161     Valid Bleu 2: 0.2931\n",
            "Valid Bleu 3:  0.2229     Valid Bleu 4:  0.1753\n",
            "Test Bleu 1:  0.429     Test Bleu 2:  0.3\n",
            "Test Bleu 3:  0.2243     Test Bleu 4:  0.1726\n",
            "\n",
            "\n",
            "Loading checkpoint shards: 100%|██████████████████| 2/2 [00:04<00:00,  2.05s/it]\n",
            "You are resizing the embedding layer without providing a `pad_to_multiple_of` parameter. This means that the new embeding dimension will be 32101. This might induce some performance reduction as *Tensor Cores* will not be available. For more details  about this, or help on choosing the correct value for resizing, refer to this guide: https://docs.nvidia.com/deeplearning/performance/dl-performance-matrix-multiplication/index.html#requirements-tc\n",
            "/opt/conda/lib/python3.8/site-packages/datasets/load.py:2072: FutureWarning: 'use_auth_token' was deprecated in favor of 'token' in version 2.14.0 and will be removed in 3.0.0.\n",
            "You can remove this warning by passing 'token=False' instead.\n",
            "  warnings.warn(\n",
            "\n",
            "\n",
            "Evaluation Time:  2:33:03\n",
            "Valid Bleu 1:  0.5252     Valid Bleu 2: 0.3825\n",
            "Valid Bleu 3:  0.2988     Valid Bleu 4:  0.2404\n",
            "Test Bleu 1:  0.5382     Test Bleu 2:  0.3893\n",
            "Test Bleu 3:  0.3     Test Bleu 4:  0.2371\n",
            "\n",
            "\n",
            "Loading checkpoint shards: 100%|██████████████████| 2/2 [00:04<00:00,  2.04s/it]\n",
            "You are resizing the embedding layer without providing a `pad_to_multiple_of` parameter. This means that the new embeding dimension will be 32101. This might induce some performance reduction as *Tensor Cores* will not be available. For more details  about this, or help on choosing the correct value for resizing, refer to this guide: https://docs.nvidia.com/deeplearning/performance/dl-performance-matrix-multiplication/index.html#requirements-tc\n",
            "/opt/conda/lib/python3.8/site-packages/datasets/load.py:2072: FutureWarning: 'use_auth_token' was deprecated in favor of 'token' in version 2.14.0 and will be removed in 3.0.0.\n",
            "You can remove this warning by passing 'token=False' instead.\n",
            "  warnings.warn(\n",
            "\n",
            "\n",
            "Evaluation Time:  2:26:22\n",
            "Valid Bleu 1:  0.5642     Valid Bleu 2: 0.4171\n",
            "Valid Bleu 3:  0.329     Valid Bleu 4:  0.2667\n",
            "Test Bleu 1:  0.5797     Test Bleu 2:  0.4254\n",
            "Test Bleu 3:  0.3315     Test Bleu 4:  0.264\n",
            "\n",
            "\n",
            "Loading checkpoint shards: 100%|██████████████████| 2/2 [00:04<00:00,  2.04s/it]\n",
            "You are resizing the embedding layer without providing a `pad_to_multiple_of` parameter. This means that the new embeding dimension will be 32101. This might induce some performance reduction as *Tensor Cores* will not be available. For more details  about this, or help on choosing the correct value for resizing, refer to this guide: https://docs.nvidia.com/deeplearning/performance/dl-performance-matrix-multiplication/index.html#requirements-tc\n",
            "/opt/conda/lib/python3.8/site-packages/datasets/load.py:2072: FutureWarning: 'use_auth_token' was deprecated in favor of 'token' in version 2.14.0 and will be removed in 3.0.0.\n",
            "You can remove this warning by passing 'token=False' instead.\n",
            "  warnings.warn(\n",
            "\n",
            "\n",
            "Evaluation Time:  2:24:01\n",
            "Valid Bleu 1:  0.579     Valid Bleu 2: 0.4298\n",
            "Valid Bleu 3:  0.3408     Valid Bleu 4:  0.2773\n",
            "Test Bleu 1:  0.5926     Test Bleu 2:  0.4366\n",
            "Test Bleu 3:  0.3412     Test Bleu 4:  0.2729\n",
            "\n",
            "\n",
            "Loading checkpoint shards: 100%|██████████████████| 2/2 [00:03<00:00,  2.00s/it]\n",
            "You are resizing the embedding layer without providing a `pad_to_multiple_of` parameter. This means that the new embeding dimension will be 32101. This might induce some performance reduction as *Tensor Cores* will not be available. For more details  about this, or help on choosing the correct value for resizing, refer to this guide: https://docs.nvidia.com/deeplearning/performance/dl-performance-matrix-multiplication/index.html#requirements-tc\n",
            "/opt/conda/lib/python3.8/site-packages/datasets/load.py:2072: FutureWarning: 'use_auth_token' was deprecated in favor of 'token' in version 2.14.0 and will be removed in 3.0.0.\n",
            "You can remove this warning by passing 'token=False' instead.\n",
            "  warnings.warn(\n",
            "\n",
            "\n",
            "Evaluation Time:  2:24:42\n",
            "Valid Bleu 1:  0.5782     Valid Bleu 2: 0.429\n",
            "Valid Bleu 3:  0.3398     Valid Bleu 4:  0.2762\n",
            "Test Bleu 1:  0.5926     Test Bleu 2:  0.437\n",
            "Test Bleu 3:  0.3414     Test Bleu 4:  0.2727\n",
            "\n",
            "\n",
            "Loading checkpoint shards: 100%|██████████████████| 2/2 [00:03<00:00,  1.80s/it]\n",
            "You are resizing the embedding layer without providing a `pad_to_multiple_of` parameter. This means that the new embeding dimension will be 32101. This might induce some performance reduction as *Tensor Cores* will not be available. For more details  about this, or help on choosing the correct value for resizing, refer to this guide: https://docs.nvidia.com/deeplearning/performance/dl-performance-matrix-multiplication/index.html#requirements-tc\n",
            "/opt/conda/lib/python3.8/site-packages/datasets/load.py:2072: FutureWarning: 'use_auth_token' was deprecated in favor of 'token' in version 2.14.0 and will be removed in 3.0.0.\n",
            "You can remove this warning by passing 'token=False' instead.\n",
            "  warnings.warn(\n",
            "\n",
            "\n",
            "Evaluation Time:  2:24:47\n",
            "Valid Bleu 1:  0.5793     Valid Bleu 2: 0.4298\n",
            "Valid Bleu 3:  0.3402     Valid Bleu 4:  0.2767\n",
            "Test Bleu 1:  0.5957     Test Bleu 2:  0.4395\n",
            "Test Bleu 3:  0.3437     Test Bleu 4:  0.2748\n",
            "\n",
            "\n",
            "Loading checkpoint shards: 100%|██████████████████| 2/2 [00:04<00:00,  2.01s/it]\n",
            "You are resizing the embedding layer without providing a `pad_to_multiple_of` parameter. This means that the new embeding dimension will be 32101. This might induce some performance reduction as *Tensor Cores* will not be available. For more details  about this, or help on choosing the correct value for resizing, refer to this guide: https://docs.nvidia.com/deeplearning/performance/dl-performance-matrix-multiplication/index.html#requirements-tc\n",
            "/opt/conda/lib/python3.8/site-packages/datasets/load.py:2072: FutureWarning: 'use_auth_token' was deprecated in favor of 'token' in version 2.14.0 and will be removed in 3.0.0.\n",
            "You can remove this warning by passing 'token=False' instead.\n",
            "  warnings.warn(\n",
            "\n",
            "\n",
            "Evaluation Time:  2:23:06\n",
            "Valid Bleu 1:  0.5873     Valid Bleu 2: 0.4362\n",
            "Valid Bleu 3:  0.3454     Valid Bleu 4:  0.2808\n",
            "Test Bleu 1:  0.6041     Test Bleu 2:  0.4467\n",
            "Test Bleu 3:  0.3504     Test Bleu 4:  0.2807\n",
            "\n",
            "\n",
            "Loading checkpoint shards: 100%|██████████████████| 2/2 [00:03<00:00,  1.85s/it]\n",
            "You are resizing the embedding layer without providing a `pad_to_multiple_of` parameter. This means that the new embeding dimension will be 32101. This might induce some performance reduction as *Tensor Cores* will not be available. For more details  about this, or help on choosing the correct value for resizing, refer to this guide: https://docs.nvidia.com/deeplearning/performance/dl-performance-matrix-multiplication/index.html#requirements-tc\n",
            "/opt/conda/lib/python3.8/site-packages/datasets/load.py:2072: FutureWarning: 'use_auth_token' was deprecated in favor of 'token' in version 2.14.0 and will be removed in 3.0.0.\n",
            "You can remove this warning by passing 'token=False' instead.\n",
            "  warnings.warn(\n",
            "\n",
            "\n",
            "Evaluation Time:  2:24:56\n",
            "Valid Bleu 1:  0.5843     Valid Bleu 2: 0.4344\n",
            "Valid Bleu 3:  0.3445     Valid Bleu 4:  0.2803\n",
            "Test Bleu 1:  0.5961     Test Bleu 2:  0.44\n",
            "Test Bleu 3:  0.3446     Test Bleu 4:  0.2756\n",
            "\n",
            "\n",
            "Loading checkpoint shards: 100%|██████████████████| 2/2 [00:04<00:00,  2.07s/it]\n",
            "You are resizing the embedding layer without providing a `pad_to_multiple_of` parameter. This means that the new embeding dimension will be 32101. This might induce some performance reduction as *Tensor Cores* will not be available. For more details  about this, or help on choosing the correct value for resizing, refer to this guide: https://docs.nvidia.com/deeplearning/performance/dl-performance-matrix-multiplication/index.html#requirements-tc\n",
            "/opt/conda/lib/python3.8/site-packages/datasets/load.py:2072: FutureWarning: 'use_auth_token' was deprecated in favor of 'token' in version 2.14.0 and will be removed in 3.0.0.\n",
            "You can remove this warning by passing 'token=False' instead.\n",
            "  warnings.warn(\n",
            "\n",
            "\n",
            "Evaluation Time:  2:23:59\n",
            "Valid Bleu 1:  0.5871     Valid Bleu 2: 0.4364\n",
            "Valid Bleu 3:  0.3457     Valid Bleu 4:  0.281\n",
            "Test Bleu 1:  0.6007     Test Bleu 2:  0.4434\n",
            "Test Bleu 3:  0.3473     Test Bleu 4:  0.2779\n",
            "\n",
            "\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Waiting for W&B process to finish... \u001b[32m(success).\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Run history:\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:  test_bleu_1 ▁▄▇▇██████\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:  test_bleu_2 ▁▄▆▇██████\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:  test_bleu_3 ▁▄▆▇██████\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:  test_bleu_4 ▁▄▆▇██████\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: valid_bleu_1 ▁▄▇▇██████\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: valid_bleu_2 ▁▄▆▇██████\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: valid_bleu_3 ▁▄▆▇██████\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: valid_bleu_4 ▁▄▆▇██████\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Run summary:\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:  test_bleu_1 0.60067\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:  test_bleu_2 0.44343\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:  test_bleu_3 0.34732\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:  test_bleu_4 0.27788\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: valid_bleu_1 0.58713\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: valid_bleu_2 0.43637\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: valid_bleu_3 0.34574\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: valid_bleu_4 0.28099\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: 🚀 View run \u001b[33mflan_t5_xl_squad_qg_lora_r128_al32\u001b[0m at: \u001b[34m\u001b[4mhttps://wandb.ai/minseok0809/lmqg_qg_squad/runs/gti4mgrf\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Find logs at: \u001b[35m\u001b[1m./wandb/run-20230909_110654-gti4mgrf/logs\u001b[0m\n"
          ]
        }
      ],
      "source": [
        "!python -m lm-question-generation.lmqg.grid_searcher_flan_t5_xl_squad_qg_lora_r128_al32_evaluation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "wandb.finish()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Flan T5 XXL Model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Original Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "!python -m lm-question-generation.lmqg.grid_searcher_flan_t5_xxl_squad_qg"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {},
      "outputs": [],
      "source": [
        "wandb.finish()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Lora Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "!python -m lm-question-generation.lmqg.grid_searcher_flan_t5_xxl_squad_qg_lora_r1_al32_training "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "!python -m lm-question-generation.lmqg.grid_searcher_flan_t5_xxl_squad_qg_lora_r1_al32_evaluation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "!python -m lm-question-generation.lmqg.grid_searcher_flan_t5_xxl_squad_qg_lora_r8_al32_training "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "!python -m lm-question-generation.lmqg.grid_searcher_flan_t5_xxl_squad_qg_lora_r8_al32_evaluation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "wandb.finish()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "erRMsEx-zJbX"
      },
      "source": [
        "## T5 Small Model Grid Search"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from lmqg import GridSearcher\n",
        "\n",
        "trainer = GridSearcher(\n",
        "    checkpoint_dir='tmp_ckpt_t5_small_0819',\n",
        "    dataset_path='lmqg/qg_squad',\n",
        "    model='t5-small',\n",
        "    epoch=3,\n",
        "    epoch_partial=1,\n",
        "    batch=64,\n",
        "    n_max_config=5,\n",
        "    gradient_accumulation_steps=[2], \n",
        "    lr=[1e-04],\n",
        "    label_smoothing=[0, 0.15]\n",
        ")\n",
        "trainer.run()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Grid Search\n",
        "<br>gradient_accumulation_steps=[2, 4], \n",
        "<br>lr=[1e-04, 5e-04, 1e-03],\n",
        "<br>label_smoothing=[0, 0.15]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "The number of model: \n",
        "<br>gradient_accumulation_steps * lr * label_smoothing \n",
        "<br>3 * 2 * 2 = 12"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 58,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Best Model of T5 Small\n",
            "\n",
            "_name_or_path : tmp_ckpt/model_cghqta/epoch_5\n",
            "model : t5-small\n",
            "epoch : 12\n",
            "batch : 64\n",
            "lr : 0.0005  [Grid Search Result]\n",
            "gradient_accumulation_steps : 4  [Grid Search Result]\n",
            "label_smoothing : 0.15  [Grid Search Result]\n"
          ]
        }
      ],
      "source": [
        "with open('tmp_ckpt_t5_small_0818/best_model/config.json', 'r') as f:\n",
        "    t5_small_best_model_config = json.load(f)\n",
        "\n",
        "with open('tmp_ckpt_t5_small_0818/best_model/trainer_config.json', 'r') as f:\n",
        "    t5_small_best_model_hyperparameter_search = json.load(f)\n",
        "\n",
        "hyperparameters = ['model', 'epoch', 'batch',\n",
        "                   'lr', 'gradient_accumulation_steps', 'label_smoothing']\n",
        "grid_serach_hyperparameter = ['lr', 'gradient_accumulation_steps', 'label_smoothing']\n",
        "\n",
        "print(colored(\"Best Model of T5 Small\", attrs=['bold']))\n",
        "print()\n",
        "for value, key in t5_small_best_model_config.items():\n",
        "    if '_name_or_path' in value:\n",
        "        print(\"{} : {}\".format(value, key))   \n",
        "    \n",
        "for value, key in t5_small_best_model_hyperparameter_search.items():\n",
        "    if any(hyperparameter in value for hyperparameter in hyperparameters):\n",
        "        if any(hyperparameter in value for hyperparameter in grid_serach_hyperparameter):\n",
        "            print(\"{} : {}  [Grid Search Result]\".format(value, key))\n",
        "        else:\n",
        "            print(\"{} : {}\".format(value, key))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Best T5 SmallModel"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### End2end QAG"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# lmqg/t5-small-squad-qag\n",
        "CUDA_VISIBLE_DEVICES=\"0\"\n",
        "\n",
        "!python -m lm-question-generation.lmqg.grid_searcher_t5_small_squad_qag \\\n",
        "#    --checkpoint_dir='tmp_ckpt_t5_small_squad_qag_0821' \\\n",
        "#    --dataset_path='lmqg/qg_squadshifts' \\\n",
        "#    --dataset_name='all' \\\n",
        "#    --model='t5-small' \\\n",
        "#    --epoch=15 \\\n",
        "#    --epoch_partial=5 \\\n",
        "#    --batch=64 \\\n",
        "#    --n_max_config=5 \\\n",
        "#    --gradient_accumulation_steps=[4] \\\n",
        "#    --lr=[5e-04] \\\n",
        "#    --label_smoothing=[0, 0.15] \\\n",
        "#    --language=\"en\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Multitask QAG"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "CUDA_VISIBLE_DEVICES=\"0\"\n",
        "\n",
        "!python -m lm-question-generation.lmqg.grid_searcher_t5_small_squad_qg_ae \\\n",
        "#    --checkpoint_dir='tmp_ckpt_t5_small_squad_qg_ae_0821 \\\n",
        "#    --dataset_path='lmqg/qg_squadshifts' \\\n",
        "#    --dataset_name='all' \\\n",
        "#    --model='t5-small' \\\n",
        "#    --epoch=15 \\\n",
        "#    --epoch_partial=5 \\\n",
        "#    --batch=64 \\\n",
        "#    --n_max_config=5 \\\n",
        "#    --gradient_accumulation_steps=[4] \\\n",
        "#    --lr=[5e-04] \\\n",
        "#    --label_smoothing=[0, 0.15] \\\n",
        "#    --language=\"en\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Pipeline QAG"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "CUDA_VISIBLE_DEVICES=\"0\"\n",
        "\n",
        "!python -m lm-question-generation.lmqg.grid_searcher_t5_small_squad_qg \\\n",
        "#    --checkpoint_dir='tmp_ckpt_t5_small_squad_qg_0821 \\\n",
        "#    --dataset_path='lmqg/t5-small-squad-qg' \\\n",
        "#    --dataset_name='all' \\\n",
        "#    --model='t5-small' \\\n",
        "#    --epoch=15 \\\n",
        "#    --epoch_partial=5 \\\n",
        "#    --batch=64 \\\n",
        "#    --n_max_config=5 \\\n",
        "#    --gradient_accumulation_steps=[4] \\\n",
        "#    --lr=[5e-04] \\\n",
        "#    --label_smoothing=[0, 0.15] \\\n",
        "#    --language=\"en\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Source"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "[lmqg/t5-small-squad-qa](https://huggingface.co/lmqg/t5-small-squad-qa)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.12"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
