{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "teHzLo4owK3j"
      },
      "source": [
        "## LMQG Model Development (Libra Device 0)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "<b>Model</b>\n",
        "<br>T5 Small / BART Base / T5 Base / T5 Large / BART Large\n",
        "<br>Gold QA (i.e., the model using the human-labeled gold\n",
        "annotations)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "<b>QAG approaches</b>\n",
        "<br>End2Endv / MultiTask / Pipeline"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "<b>Dataset</b>\n",
        "<br>SQuADShifts (Amazon / Wiki / NYT / Reddit)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "<b>Experiment</b>\n",
        "<br>All / Amazon / Wiki / NYT / Reddit"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "L6m9o9YV0j7O"
      },
      "outputs": [],
      "source": [
        "%pip install lmqg\n",
        "%pip install peft\n",
        "%pip install easydict\n",
        "%pip install termcolor\n",
        "%pip install openpyxl\n",
        "%pip install ipywidgets\n",
        "!python -m spacy download en"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "XrYqvzLjZwev"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import json\n",
        "import torch\n",
        "from pprint import pprint\n",
        "# from termcolor import coloredg\n",
        "from lmqg import TransformersQG"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "True\n",
            "2\n",
            "NVIDIA GeForce RTX 4090\n"
          ]
        }
      ],
      "source": [
        "print(torch.cuda.is_available())\n",
        "print(torch.cuda.device_count())\n",
        "print(torch.cuda.get_device_name(torch.cuda.current_device()))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'/'"
            ]
          },
          "execution_count": 3,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "pwd"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "/workspace\n"
          ]
        }
      ],
      "source": [
        "cd workspace"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [],
      "source": [
        "import torch\n",
        "torch.cuda.empty_cache()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [],
      "source": [
        "import torch, gc\n",
        "gc.collect()\n",
        "torch.cuda.empty_cache()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {},
      "outputs": [],
      "source": [
        "os.environ[\"CUDA_DEVICE_ORDER\"]=\"PCI_BUS_ID\"\n",
        "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"0\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mminseok0809\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "execution_count": 8,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import wandb\n",
        "\n",
        "wandb.login()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Flan T5 Small Model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Original Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "!python -m lm-question-generation.lmqg.grid_searcher_flan_t5_small_squad_qg"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {},
      "outputs": [],
      "source": [
        "wandb.finish()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Lora Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "!python -m lm-question-generation.lmqg.grid_searcher_flan_t5_small_squad_qg_lora_r8_al16"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "!python -m lm-question-generation.lmqg.grid_searcher_flan_t5_small_squad_qg_lora_r16_al16"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "!python -m lm-question-generation.lmqg.grid_searcher_flan_t5_small_squad_qg_lora_r32_al16"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "!python -m lm-question-generation.lmqg.grid_searcher_flan_t5_small_squad_qg_lora_r64_al16"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "!python -m lm-question-generation.lmqg.grid_searcher_flan_t5_small_squad_qg_lora_r128_al16"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "!python -m lm-question-generation.lmqg.grid_searcher_flan_t5_small_squad_qg_lora_r8_al32"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "!python -m lm-question-generation.lmqg.grid_searcher_flan_t5_small_squad_qg_lora_r16_al32"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "!python -m lm-question-generation.lmqg.grid_searcher_flan_t5_small_squad_qg_lora_r32_al32"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "!python -m lm-question-generation.lmqg.grid_searcher_flan_t5_small_squad_qg_lora_r64_al32"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "!python -m lm-question-generation.lmqg.grid_searcher_flan_t5_small_squad_qg_lora_r128_al32"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {},
      "outputs": [],
      "source": [
        "wandb.finish()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Flan T5 Large Model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Original Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "!python -m lm-question-generation.lmqg.grid_searcher_flan_t5_large_squad_qg"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "wandb.finish()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Lora Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "!python -m lm-question-generation.lmqg.grid_searcher_flan_t5_large_squad_qg_lora_r1_al32_training "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "!python -m lm-question-generation.lmqg.grid_searcher_flan_t5_large_squad_qg_lora_r1_al32_evaluation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "!python -m lm-question-generation.lmqg.grid_searcher_flan_t5_large_squad_qg_lora_r2_al32_training "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "!python -m lm-question-generation.lmqg.grid_searcher_flan_t5_large_squad_qg_lora_r2_al32_evaluation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mminseok0809\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: wandb version 0.15.10 is available!  To upgrade, please run:\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:  $ pip install wandb --upgrade\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.15.9\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Run data is saved locally in \u001b[35m\u001b[1m/workspace/wandb/run-20230910_113343-y6sn34vp\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Run \u001b[1m`wandb offline`\u001b[0m to turn off syncing.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Syncing run \u001b[33mflan_t5_large_squad_qg_lora_r4_al32\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: ⭐️ View project at \u001b[34m\u001b[4mhttps://wandb.ai/minseok0809/lmqg_qg_squad\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: 🚀 View run at \u001b[34m\u001b[4mhttps://wandb.ai/minseok0809/lmqg_qg_squad/runs/y6sn34vp\u001b[0m\n",
            "/opt/conda/lib/python3.8/site-packages/transformers/models/auto/tokenization_auto.py:631: FutureWarning: The `use_auth_token` argument is deprecated and will be removed in v5 of Transformers.\n",
            "  warnings.warn(\n",
            "/opt/conda/lib/python3.8/site-packages/transformers/models/auto/configuration_auto.py:995: FutureWarning: The `use_auth_token` argument is deprecated and will be removed in v5 of Transformers.\n",
            "  warnings.warn(\n",
            "/opt/conda/lib/python3.8/site-packages/transformers/modeling_utils.py:2310: FutureWarning: The `use_auth_token` argument is deprecated and will be removed in v5 of Transformers.\n",
            "  warnings.warn(\n",
            "/opt/conda/lib/python3.8/site-packages/transformers/utils/hub.py:373: FutureWarning: The `use_auth_token` argument is deprecated and will be removed in v5 of Transformers.\n",
            "  warnings.warn(\n",
            "You are resizing the embedding layer without providing a `pad_to_multiple_of` parameter. This means that the new embeding dimension will be 32101. This might induce some performance reduction as *Tensor Cores* will not be available. For more details  about this, or help on choosing the correct value for resizing, refer to this guide: https://docs.nvidia.com/deeplearning/performance/dl-performance-matrix-multiplication/index.html#requirements-tc\n",
            "\n",
            "\n",
            "trainable model parameters: 1179648\n",
            "all model parameters: 784274432\n",
            "percentage of trainable model parameters: 0.15% \n",
            "\n",
            "/opt/conda/lib/python3.8/site-packages/datasets/load.py:2072: FutureWarning: 'use_auth_token' was deprecated in favor of 'token' in version 2.14.0 and will be removed in 3.0.0.\n",
            "You can remove this warning by passing 'token=False' instead.\n",
            "  warnings.warn(\n",
            "\n",
            "\n",
            "Epoch 1: 100%|██████████████████████████| 18792/18792 [1:06:05<00:00,  4.74it/s]\n",
            "Loss :   7.9123\n",
            "\n",
            "\n",
            "Epoch 2: 100%|██████████████████████████| 18792/18792 [1:06:18<00:00,  4.72it/s]\n",
            "Loss :   0.8281\n",
            "\n",
            "\n",
            "Epoch 3: 100%|██████████████████████████| 18792/18792 [1:06:28<00:00,  4.71it/s]\n",
            "Loss :   0.7594\n",
            "\n",
            "\n",
            "Epoch 4: 100%|██████████████████████████| 18792/18792 [1:06:35<00:00,  4.70it/s]\n",
            "Loss :   0.7292\n",
            "\n",
            "\n",
            "Epoch 5: 100%|██████████████████████████| 18792/18792 [1:06:27<00:00,  4.71it/s]\n",
            "Loss :   0.7099\n",
            "\n",
            "\n",
            "Epoch 6: 100%|██████████████████████████| 18792/18792 [1:06:32<00:00,  4.71it/s]\n",
            "Loss :   0.6939\n",
            "\n",
            "\n",
            "Epoch 7: 100%|██████████████████████████| 18792/18792 [1:06:27<00:00,  4.71it/s]\n",
            "Loss :   0.672\n",
            "\n",
            "\n",
            "Epoch 8: 100%|██████████████████████████| 18792/18792 [1:06:32<00:00,  4.71it/s]\n",
            "Loss :   0.651\n",
            "\n",
            "\n",
            "Epoch 9: 100%|██████████████████████████| 18792/18792 [1:06:35<00:00,  4.70it/s]\n",
            "Loss :   0.6382\n",
            "\n",
            "\n",
            "Epoch 10: 100%|█████████████████████████| 18792/18792 [1:06:30<00:00,  4.71it/s]\n",
            "Loss :   0.6291\n",
            "\n",
            "\n",
            "Epoch 11: 100%|█████████████████████████| 18792/18792 [1:06:27<00:00,  4.71it/s]\n",
            "Loss :   0.623\n",
            "\n",
            "\n",
            "Epoch 12: 100%|█████████████████████████| 18792/18792 [1:06:24<00:00,  4.72it/s]\n",
            "Loss :   0.6189\n",
            "\n",
            "\n",
            "Epoch 13: 100%|█████████████████████████| 18792/18792 [1:06:36<00:00,  4.70it/s]\n",
            "Loss :   0.6148\n",
            "\n",
            "\n",
            "Epoch 14: 100%|█████████████████████████| 18792/18792 [1:06:26<00:00,  4.71it/s]\n",
            "Loss :   0.6109\n",
            "\n",
            "\n",
            "Epoch 15: 100%|█████████████████████████| 18792/18792 [1:06:42<00:00,  4.70it/s]\n",
            "Loss :   0.6081\n",
            "\n",
            "\n",
            "Epoch 16: 100%|█████████████████████████| 18792/18792 [1:06:38<00:00,  4.70it/s]\n",
            "Loss :   0.6052\n",
            "\n",
            "\n",
            "Epoch 17: 100%|█████████████████████████| 18792/18792 [1:06:41<00:00,  4.70it/s]\n",
            "Loss :   0.6014\n",
            "\n",
            "\n",
            "Epoch 18: 100%|█████████████████████████| 18792/18792 [1:06:47<00:00,  4.69it/s]\n",
            "Loss :   0.5998\n",
            "\n",
            "\n",
            "Epoch 19: 100%|█████████████████████████| 18792/18792 [1:06:46<00:00,  4.69it/s]\n",
            "Loss :   0.5972\n",
            "\n",
            "\n",
            "Epoch 20: 100%|█████████████████████████| 18792/18792 [1:06:48<00:00,  4.69it/s]\n",
            "Loss :   0.5954\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Waiting for W&B process to finish... \u001b[32m(success).\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: / 0.006 MB of 0.013 MB uploaded (0.000 MB deduped)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Run history:\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: loss █▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Run summary:\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: loss 0.5954\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: 🚀 View run \u001b[33mflan_t5_large_squad_qg_lora_r4_al32\u001b[0m at: \u001b[34m\u001b[4mhttps://wandb.ai/minseok0809/lmqg_qg_squad/runs/y6sn34vp\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Find logs at: \u001b[35m\u001b[1m./wandb/run-20230910_113343-y6sn34vp/logs\u001b[0m\n"
          ]
        }
      ],
      "source": [
        "!python -m lm-question-generation.lmqg.grid_searcher_flan_t5_large_squad_qg_lora_r4_al32_training "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mminseok0809\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: wandb version 0.15.10 is available!  To upgrade, please run:\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:  $ pip install wandb --upgrade\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.15.9\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Run data is saved locally in \u001b[35m\u001b[1m/workspace/wandb/run-20230911_094518-0vz925ou\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Run \u001b[1m`wandb offline`\u001b[0m to turn off syncing.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Syncing run \u001b[33mflan_t5_large_squad_qg_lora_r4_al32\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: ⭐️ View project at \u001b[34m\u001b[4mhttps://wandb.ai/minseok0809/lmqg_qg_squad\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: 🚀 View run at \u001b[34m\u001b[4mhttps://wandb.ai/minseok0809/lmqg_qg_squad/runs/0vz925ou\u001b[0m\n",
            "You are resizing the embedding layer without providing a `pad_to_multiple_of` parameter. This means that the new embeding dimension will be 32101. This might induce some performance reduction as *Tensor Cores* will not be available. For more details  about this, or help on choosing the correct value for resizing, refer to this guide: https://docs.nvidia.com/deeplearning/performance/dl-performance-matrix-multiplication/index.html#requirements-tc\n",
            "/opt/conda/lib/python3.8/site-packages/datasets/load.py:2072: FutureWarning: 'use_auth_token' was deprecated in favor of 'token' in version 2.14.0 and will be removed in 3.0.0.\n",
            "You can remove this warning by passing 'token=False' instead.\n",
            "  warnings.warn(\n",
            "100%|███████████████████████████████████| 11877/11877 [00:04<00:00, 2743.54it/s]\n",
            "100%|███████████████████████████████████| 10570/10570 [00:04<00:00, 2399.80it/s]\n",
            "\n",
            "\n",
            "Evaluation Time:  1:33:19\n",
            "Valid Bleu 1:  0.1956     Valid Bleu 2: 0.1069\n",
            "Valid Bleu 3:  0.0676     Valid Bleu 4:  0.0462\n",
            "Test Bleu 1:  0.2043     Test Bleu 2:  0.1124\n",
            "Test Bleu 3:  0.0703     Test Bleu 4:  0.0472\n",
            "\n",
            "\n",
            "You are resizing the embedding layer without providing a `pad_to_multiple_of` parameter. This means that the new embeding dimension will be 32101. This might induce some performance reduction as *Tensor Cores* will not be available. For more details  about this, or help on choosing the correct value for resizing, refer to this guide: https://docs.nvidia.com/deeplearning/performance/dl-performance-matrix-multiplication/index.html#requirements-tc\n",
            "/opt/conda/lib/python3.8/site-packages/datasets/load.py:2072: FutureWarning: 'use_auth_token' was deprecated in favor of 'token' in version 2.14.0 and will be removed in 3.0.0.\n",
            "You can remove this warning by passing 'token=False' instead.\n",
            "  warnings.warn(\n",
            "\n",
            "\n",
            "Evaluation Time:  1:31:04\n",
            "Valid Bleu 1:  0.2652     Valid Bleu 2: 0.1657\n",
            "Valid Bleu 3:  0.1156     Valid Bleu 4:  0.0849\n",
            "Test Bleu 1:  0.2629     Test Bleu 2:  0.162\n",
            "Test Bleu 3:  0.1102     Test Bleu 4:  0.0787\n",
            "\n",
            "\n",
            "You are resizing the embedding layer without providing a `pad_to_multiple_of` parameter. This means that the new embeding dimension will be 32101. This might induce some performance reduction as *Tensor Cores* will not be available. For more details  about this, or help on choosing the correct value for resizing, refer to this guide: https://docs.nvidia.com/deeplearning/performance/dl-performance-matrix-multiplication/index.html#requirements-tc\n",
            "/opt/conda/lib/python3.8/site-packages/datasets/load.py:2072: FutureWarning: 'use_auth_token' was deprecated in favor of 'token' in version 2.14.0 and will be removed in 3.0.0.\n",
            "You can remove this warning by passing 'token=False' instead.\n",
            "  warnings.warn(\n",
            "\n",
            "\n",
            "Evaluation Time:  1:26:29\n",
            "Valid Bleu 1:  0.3722     Valid Bleu 2: 0.2527\n",
            "Valid Bleu 3:  0.1869     Valid Bleu 4:  0.1433\n",
            "Test Bleu 1:  0.3616     Test Bleu 2:  0.2411\n",
            "Test Bleu 3:  0.1744     Test Bleu 4:  0.1309\n",
            "\n",
            "\n",
            "You are resizing the embedding layer without providing a `pad_to_multiple_of` parameter. This means that the new embeding dimension will be 32101. This might induce some performance reduction as *Tensor Cores* will not be available. For more details  about this, or help on choosing the correct value for resizing, refer to this guide: https://docs.nvidia.com/deeplearning/performance/dl-performance-matrix-multiplication/index.html#requirements-tc\n",
            "/opt/conda/lib/python3.8/site-packages/datasets/load.py:2072: FutureWarning: 'use_auth_token' was deprecated in favor of 'token' in version 2.14.0 and will be removed in 3.0.0.\n",
            "You can remove this warning by passing 'token=False' instead.\n",
            "  warnings.warn(\n",
            "\n",
            "\n",
            "Evaluation Time:  1:19:35\n",
            "Valid Bleu 1:  0.4935     Valid Bleu 2: 0.3542\n",
            "Valid Bleu 3:  0.2738     Valid Bleu 4:  0.218\n",
            "Test Bleu 1:  0.4951     Test Bleu 2:  0.3505\n",
            "Test Bleu 3:  0.2653     Test Bleu 4:  0.2061\n",
            "\n",
            "\n",
            "You are resizing the embedding layer without providing a `pad_to_multiple_of` parameter. This means that the new embeding dimension will be 32101. This might induce some performance reduction as *Tensor Cores* will not be available. For more details  about this, or help on choosing the correct value for resizing, refer to this guide: https://docs.nvidia.com/deeplearning/performance/dl-performance-matrix-multiplication/index.html#requirements-tc\n",
            "/opt/conda/lib/python3.8/site-packages/datasets/load.py:2072: FutureWarning: 'use_auth_token' was deprecated in favor of 'token' in version 2.14.0 and will be removed in 3.0.0.\n",
            "You can remove this warning by passing 'token=False' instead.\n",
            "  warnings.warn(\n",
            "\n",
            "\n",
            "Evaluation Time:  1:16:06\n",
            "Valid Bleu 1:  0.5433     Valid Bleu 2: 0.396\n",
            "Valid Bleu 3:  0.3093     Valid Bleu 4:  0.2484\n",
            "Test Bleu 1:  0.5534     Test Bleu 2:  0.3992\n",
            "Test Bleu 3:  0.3066     Test Bleu 4:  0.2414\n",
            "\n",
            "\n",
            "You are resizing the embedding layer without providing a `pad_to_multiple_of` parameter. This means that the new embeding dimension will be 32101. This might induce some performance reduction as *Tensor Cores* will not be available. For more details  about this, or help on choosing the correct value for resizing, refer to this guide: https://docs.nvidia.com/deeplearning/performance/dl-performance-matrix-multiplication/index.html#requirements-tc\n",
            "/opt/conda/lib/python3.8/site-packages/datasets/load.py:2072: FutureWarning: 'use_auth_token' was deprecated in favor of 'token' in version 2.14.0 and will be removed in 3.0.0.\n",
            "You can remove this warning by passing 'token=False' instead.\n",
            "  warnings.warn(\n",
            "\n",
            "\n",
            "Evaluation Time:  1:14:02\n",
            "Valid Bleu 1:  0.5651     Valid Bleu 2: 0.4149\n",
            "Valid Bleu 3:  0.3257     Valid Bleu 4:  0.2626\n",
            "Test Bleu 1:  0.5769     Test Bleu 2:  0.419\n",
            "Test Bleu 3:  0.3238     Test Bleu 4:  0.2562\n",
            "\n",
            "\n",
            "You are resizing the embedding layer without providing a `pad_to_multiple_of` parameter. This means that the new embeding dimension will be 32101. This might induce some performance reduction as *Tensor Cores* will not be available. For more details  about this, or help on choosing the correct value for resizing, refer to this guide: https://docs.nvidia.com/deeplearning/performance/dl-performance-matrix-multiplication/index.html#requirements-tc\n",
            "/opt/conda/lib/python3.8/site-packages/datasets/load.py:2072: FutureWarning: 'use_auth_token' was deprecated in favor of 'token' in version 2.14.0 and will be removed in 3.0.0.\n",
            "You can remove this warning by passing 'token=False' instead.\n",
            "  warnings.warn(\n",
            "\n",
            "\n",
            "Evaluation Time:  1:13:06\n",
            "Valid Bleu 1:  0.5744     Valid Bleu 2: 0.423\n",
            "Valid Bleu 3:  0.3327     Valid Bleu 4:  0.2686\n",
            "Test Bleu 1:  0.5877     Test Bleu 2:  0.4282\n",
            "Test Bleu 3:  0.3312     Test Bleu 4:  0.2622\n",
            "\n",
            "\n",
            "You are resizing the embedding layer without providing a `pad_to_multiple_of` parameter. This means that the new embeding dimension will be 32101. This might induce some performance reduction as *Tensor Cores* will not be available. For more details  about this, or help on choosing the correct value for resizing, refer to this guide: https://docs.nvidia.com/deeplearning/performance/dl-performance-matrix-multiplication/index.html#requirements-tc\n",
            "/opt/conda/lib/python3.8/site-packages/datasets/load.py:2072: FutureWarning: 'use_auth_token' was deprecated in favor of 'token' in version 2.14.0 and will be removed in 3.0.0.\n",
            "You can remove this warning by passing 'token=False' instead.\n",
            "  warnings.warn(\n",
            "\n",
            "\n",
            "Evaluation Time:  1:12:11\n",
            "Valid Bleu 1:  0.5787     Valid Bleu 2: 0.4279\n",
            "Valid Bleu 3:  0.3376     Valid Bleu 4:  0.2734\n",
            "Test Bleu 1:  0.5905     Test Bleu 2:  0.4308\n",
            "Test Bleu 3:  0.3338     Test Bleu 4:  0.2647\n",
            "\n",
            "\n",
            "You are resizing the embedding layer without providing a `pad_to_multiple_of` parameter. This means that the new embeding dimension will be 32101. This might induce some performance reduction as *Tensor Cores* will not be available. For more details  about this, or help on choosing the correct value for resizing, refer to this guide: https://docs.nvidia.com/deeplearning/performance/dl-performance-matrix-multiplication/index.html#requirements-tc\n",
            "/opt/conda/lib/python3.8/site-packages/datasets/load.py:2072: FutureWarning: 'use_auth_token' was deprecated in favor of 'token' in version 2.14.0 and will be removed in 3.0.0.\n",
            "You can remove this warning by passing 'token=False' instead.\n",
            "  warnings.warn(\n",
            "\n",
            "\n",
            "Evaluation Time:  1:12:05\n",
            "Valid Bleu 1:  0.5821     Valid Bleu 2: 0.4311\n",
            "Valid Bleu 3:  0.3405     Valid Bleu 4:  0.276\n",
            "Test Bleu 1:  0.5924     Test Bleu 2:  0.4327\n",
            "Test Bleu 3:  0.3355     Test Bleu 4:  0.266\n",
            "\n",
            "\n",
            "You are resizing the embedding layer without providing a `pad_to_multiple_of` parameter. This means that the new embeding dimension will be 32101. This might induce some performance reduction as *Tensor Cores* will not be available. For more details  about this, or help on choosing the correct value for resizing, refer to this guide: https://docs.nvidia.com/deeplearning/performance/dl-performance-matrix-multiplication/index.html#requirements-tc\n",
            "/opt/conda/lib/python3.8/site-packages/datasets/load.py:2072: FutureWarning: 'use_auth_token' was deprecated in favor of 'token' in version 2.14.0 and will be removed in 3.0.0.\n",
            "You can remove this warning by passing 'token=False' instead.\n",
            "  warnings.warn(\n",
            "\n",
            "\n",
            "Evaluation Time:  1:12:08\n",
            "Valid Bleu 1:  0.5797     Valid Bleu 2: 0.429\n",
            "Valid Bleu 3:  0.3387     Valid Bleu 4:  0.2746\n",
            "Test Bleu 1:  0.5921     Test Bleu 2:  0.4326\n",
            "Test Bleu 3:  0.3355     Test Bleu 4:  0.2659\n",
            "\n",
            "\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Waiting for W&B process to finish... \u001b[32m(success).\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Run history:\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:  test_bleu_1 ▁▂▄▆▇█████\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:  test_bleu_2 ▁▂▄▆▇█████\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:  test_bleu_3 ▁▂▄▆▇█████\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:  test_bleu_4 ▁▂▄▆▇█████\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: valid_bleu_1 ▁▂▄▆▇█████\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: valid_bleu_2 ▁▂▄▆▇█████\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: valid_bleu_3 ▁▂▄▆▇█████\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: valid_bleu_4 ▁▂▄▆▇█████\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Run summary:\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:  test_bleu_1 0.59215\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:  test_bleu_2 0.4326\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:  test_bleu_3 0.33553\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:  test_bleu_4 0.2659\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: valid_bleu_1 0.57968\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: valid_bleu_2 0.42901\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: valid_bleu_3 0.33874\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: valid_bleu_4 0.27459\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: 🚀 View run \u001b[33mflan_t5_large_squad_qg_lora_r4_al32\u001b[0m at: \u001b[34m\u001b[4mhttps://wandb.ai/minseok0809/lmqg_qg_squad/runs/0vz925ou\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Find logs at: \u001b[35m\u001b[1m./wandb/run-20230911_094518-0vz925ou/logs\u001b[0m\n"
          ]
        }
      ],
      "source": [
        "!python -m lm-question-generation.lmqg.grid_searcher_flan_t5_large_squad_qg_lora_r4_al32_evaluation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "!python -m lm-question-generation.lmqg.grid_searcher_flan_t5_large_squad_qg_lora_r8_al32_training"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "!python -m lm-question-generation.lmqg.grid_searcher_flan_t5_large_squad_qg_lora_r8_al32_evaluation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mminseok0809\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: wandb version 0.15.10 is available!  To upgrade, please run:\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:  $ pip install wandb --upgrade\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.15.9\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Run data is saved locally in \u001b[35m\u001b[1m/workspace/wandb/run-20230911_231131-f6asmvvc\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Run \u001b[1m`wandb offline`\u001b[0m to turn off syncing.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Syncing run \u001b[33mflan_t5_large_squad_qg_lora_r16_al32\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: ⭐️ View project at \u001b[34m\u001b[4mhttps://wandb.ai/minseok0809/lmqg_qg_squad\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: 🚀 View run at \u001b[34m\u001b[4mhttps://wandb.ai/minseok0809/lmqg_qg_squad/runs/f6asmvvc\u001b[0m\n",
            "/opt/conda/lib/python3.8/site-packages/transformers/models/auto/tokenization_auto.py:631: FutureWarning: The `use_auth_token` argument is deprecated and will be removed in v5 of Transformers.\n",
            "  warnings.warn(\n",
            "/opt/conda/lib/python3.8/site-packages/transformers/models/auto/configuration_auto.py:995: FutureWarning: The `use_auth_token` argument is deprecated and will be removed in v5 of Transformers.\n",
            "  warnings.warn(\n",
            "/opt/conda/lib/python3.8/site-packages/transformers/modeling_utils.py:2310: FutureWarning: The `use_auth_token` argument is deprecated and will be removed in v5 of Transformers.\n",
            "  warnings.warn(\n",
            "/opt/conda/lib/python3.8/site-packages/transformers/utils/hub.py:373: FutureWarning: The `use_auth_token` argument is deprecated and will be removed in v5 of Transformers.\n",
            "  warnings.warn(\n",
            "You are resizing the embedding layer without providing a `pad_to_multiple_of` parameter. This means that the new embeding dimension will be 32101. This might induce some performance reduction as *Tensor Cores* will not be available. For more details  about this, or help on choosing the correct value for resizing, refer to this guide: https://docs.nvidia.com/deeplearning/performance/dl-performance-matrix-multiplication/index.html#requirements-tc\n",
            "\n",
            "\n",
            "trainable model parameters: 4718592\n",
            "all model parameters: 787813376\n",
            "percentage of trainable model parameters: 0.60% \n",
            "\n",
            "/opt/conda/lib/python3.8/site-packages/datasets/load.py:2072: FutureWarning: 'use_auth_token' was deprecated in favor of 'token' in version 2.14.0 and will be removed in 3.0.0.\n",
            "You can remove this warning by passing 'token=False' instead.\n",
            "  warnings.warn(\n",
            "\n",
            "\n",
            "Epoch 1: 100%|██████████████████████████| 18792/18792 [1:06:07<00:00,  4.74it/s]\n",
            "Loss :   7.7738\n",
            "\n",
            "\n",
            "Epoch 2: 100%|██████████████████████████| 18792/18792 [1:06:01<00:00,  4.74it/s]\n",
            "Loss :   0.7996\n",
            "\n",
            "\n",
            "Epoch 3: 100%|██████████████████████████| 18792/18792 [1:06:28<00:00,  4.71it/s]\n",
            "Loss :   0.7259\n",
            "\n",
            "\n",
            "Epoch 4: 100%|██████████████████████████| 18792/18792 [1:06:27<00:00,  4.71it/s]\n",
            "Loss :   0.6936\n",
            "\n",
            "\n",
            "Epoch 5: 100%|██████████████████████████| 18792/18792 [1:06:32<00:00,  4.71it/s]\n",
            "Loss :   0.6676\n",
            "\n",
            "\n",
            "Epoch 6: 100%|██████████████████████████| 18792/18792 [1:06:29<00:00,  4.71it/s]\n",
            "Loss :   0.6513\n",
            "\n",
            "\n",
            "Epoch 7: 100%|██████████████████████████| 18792/18792 [1:06:29<00:00,  4.71it/s]\n",
            "Loss :   0.6386\n",
            "\n",
            "\n",
            "Epoch 8: 100%|██████████████████████████| 18792/18792 [1:06:31<00:00,  4.71it/s]\n",
            "Loss :   0.6301\n",
            "\n",
            "\n",
            "Epoch 9: 100%|██████████████████████████| 18792/18792 [1:06:33<00:00,  4.71it/s]\n",
            "Loss :   0.6237\n",
            "\n",
            "\n",
            "Epoch 10: 100%|█████████████████████████| 18792/18792 [1:06:24<00:00,  4.72it/s]\n",
            "Loss :   0.6191\n",
            "\n",
            "\n",
            "Epoch 11: 100%|█████████████████████████| 18792/18792 [1:06:34<00:00,  4.70it/s]\n",
            "Loss :   0.6142\n",
            "\n",
            "\n",
            "Epoch 12: 100%|█████████████████████████| 18792/18792 [1:06:29<00:00,  4.71it/s]\n",
            "Loss :   0.6107\n",
            "\n",
            "\n",
            "Epoch 13: 100%|█████████████████████████| 18792/18792 [1:06:28<00:00,  4.71it/s]\n",
            "Loss :   0.6066\n",
            "\n",
            "\n",
            "Epoch 14: 100%|█████████████████████████| 18792/18792 [1:06:24<00:00,  4.72it/s]\n",
            "Loss :   0.6037\n",
            "\n",
            "\n",
            "Epoch 15: 100%|█████████████████████████| 18792/18792 [1:06:32<00:00,  4.71it/s]\n",
            "Loss :   0.6006\n",
            "\n",
            "\n",
            "Epoch 16: 100%|█████████████████████████| 18792/18792 [1:06:26<00:00,  4.71it/s]\n",
            "Loss :   0.5974\n",
            "\n",
            "\n",
            "Epoch 17: 100%|█████████████████████████| 18792/18792 [1:06:37<00:00,  4.70it/s]\n",
            "Loss :   0.5947\n",
            "\n",
            "\n",
            "Epoch 18: 100%|█████████████████████████| 18792/18792 [1:06:28<00:00,  4.71it/s]\n",
            "Loss :   0.5918\n",
            "\n",
            "\n",
            "Epoch 19: 100%|█████████████████████████| 18792/18792 [1:06:37<00:00,  4.70it/s]\n",
            "Loss :   0.5898\n",
            "\n",
            "\n",
            "Epoch 20: 100%|█████████████████████████| 18792/18792 [1:06:37<00:00,  4.70it/s]\n",
            "Loss :   0.5873\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Waiting for W&B process to finish... \u001b[32m(success).\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \\ 0.006 MB of 0.006 MB uploaded (0.000 MB deduped)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Run history:\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: loss █▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Run summary:\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: loss 0.58731\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: 🚀 View run \u001b[33mflan_t5_large_squad_qg_lora_r16_al32\u001b[0m at: \u001b[34m\u001b[4mhttps://wandb.ai/minseok0809/lmqg_qg_squad/runs/f6asmvvc\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Find logs at: \u001b[35m\u001b[1m./wandb/run-20230911_231131-f6asmvvc/logs\u001b[0m\n"
          ]
        }
      ],
      "source": [
        "!python -m lm-question-generation.lmqg.grid_searcher_flan_t5_large_squad_qg_lora_r16_al32_training"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mminseok0809\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: wandb version 0.15.10 is available!  To upgrade, please run:\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:  $ pip install wandb --upgrade\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.15.9\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Run data is saved locally in \u001b[35m\u001b[1m/workspace/wandb/run-20230912_212132-kumq9u8t\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Run \u001b[1m`wandb offline`\u001b[0m to turn off syncing.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Syncing run \u001b[33mflan_t5_large_squad_qg_lora_r16_al32\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: ⭐️ View project at \u001b[34m\u001b[4mhttps://wandb.ai/minseok0809/lmqg_qg_squad\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: 🚀 View run at \u001b[34m\u001b[4mhttps://wandb.ai/minseok0809/lmqg_qg_squad/runs/kumq9u8t\u001b[0m\n",
            "You are resizing the embedding layer without providing a `pad_to_multiple_of` parameter. This means that the new embeding dimension will be 32101. This might induce some performance reduction as *Tensor Cores* will not be available. For more details  about this, or help on choosing the correct value for resizing, refer to this guide: https://docs.nvidia.com/deeplearning/performance/dl-performance-matrix-multiplication/index.html#requirements-tc\n",
            "/opt/conda/lib/python3.8/site-packages/datasets/load.py:2072: FutureWarning: 'use_auth_token' was deprecated in favor of 'token' in version 2.14.0 and will be removed in 3.0.0.\n",
            "You can remove this warning by passing 'token=False' instead.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "Evaluation Time:  1:28:20\n",
            "Valid Bleu 1:  0.274     Valid Bleu 2: 0.1675\n",
            "Valid Bleu 3:  0.1153     Valid Bleu 4:  0.0841\n",
            "Test Bleu 1:  0.2749     Test Bleu 2:  0.1681\n",
            "Test Bleu 3:  0.1148     Test Bleu 4:  0.0824\n",
            "\n",
            "\n",
            "You are resizing the embedding layer without providing a `pad_to_multiple_of` parameter. This means that the new embeding dimension will be 32101. This might induce some performance reduction as *Tensor Cores* will not be available. For more details  about this, or help on choosing the correct value for resizing, refer to this guide: https://docs.nvidia.com/deeplearning/performance/dl-performance-matrix-multiplication/index.html#requirements-tc\n",
            "/opt/conda/lib/python3.8/site-packages/datasets/load.py:2072: FutureWarning: 'use_auth_token' was deprecated in favor of 'token' in version 2.14.0 and will be removed in 3.0.0.\n",
            "You can remove this warning by passing 'token=False' instead.\n",
            "  warnings.warn(\n",
            "\n",
            "\n",
            "Evaluation Time:  1:20:08\n",
            "Valid Bleu 1:  0.45     Valid Bleu 2: 0.3146\n",
            "Valid Bleu 3:  0.2386     Valid Bleu 4:  0.1867\n",
            "Test Bleu 1:  0.4429     Test Bleu 2:  0.3053\n",
            "Test Bleu 3:  0.2267     Test Bleu 4:  0.1735\n",
            "\n",
            "\n",
            "You are resizing the embedding layer without providing a `pad_to_multiple_of` parameter. This means that the new embeding dimension will be 32101. This might induce some performance reduction as *Tensor Cores* will not be available. For more details  about this, or help on choosing the correct value for resizing, refer to this guide: https://docs.nvidia.com/deeplearning/performance/dl-performance-matrix-multiplication/index.html#requirements-tc\n",
            "/opt/conda/lib/python3.8/site-packages/datasets/load.py:2072: FutureWarning: 'use_auth_token' was deprecated in favor of 'token' in version 2.14.0 and will be removed in 3.0.0.\n",
            "You can remove this warning by passing 'token=False' instead.\n",
            "  warnings.warn(\n",
            "\n",
            "\n",
            "Evaluation Time:  1:18:38\n",
            "Valid Bleu 1:  0.492     Valid Bleu 2: 0.351\n",
            "Valid Bleu 3:  0.2697     Valid Bleu 4:  0.2136\n",
            "Test Bleu 1:  0.4968     Test Bleu 2:  0.3526\n",
            "Test Bleu 3:  0.2674     Test Bleu 4:  0.2082\n",
            "\n",
            "\n",
            "You are resizing the embedding layer without providing a `pad_to_multiple_of` parameter. This means that the new embeding dimension will be 32101. This might induce some performance reduction as *Tensor Cores* will not be available. For more details  about this, or help on choosing the correct value for resizing, refer to this guide: https://docs.nvidia.com/deeplearning/performance/dl-performance-matrix-multiplication/index.html#requirements-tc\n",
            "/opt/conda/lib/python3.8/site-packages/datasets/load.py:2072: FutureWarning: 'use_auth_token' was deprecated in favor of 'token' in version 2.14.0 and will be removed in 3.0.0.\n",
            "You can remove this warning by passing 'token=False' instead.\n",
            "  warnings.warn(\n",
            "\n",
            "\n",
            "Evaluation Time:  1:14:12\n",
            "Valid Bleu 1:  0.5473     Valid Bleu 2: 0.3989\n",
            "Valid Bleu 3:  0.3114     Valid Bleu 4:  0.2501\n",
            "Test Bleu 1:  0.5582     Test Bleu 2:  0.4023\n",
            "Test Bleu 3:  0.3089     Test Bleu 4:  0.2434\n",
            "\n",
            "\n",
            "You are resizing the embedding layer without providing a `pad_to_multiple_of` parameter. This means that the new embeding dimension will be 32101. This might induce some performance reduction as *Tensor Cores* will not be available. For more details  about this, or help on choosing the correct value for resizing, refer to this guide: https://docs.nvidia.com/deeplearning/performance/dl-performance-matrix-multiplication/index.html#requirements-tc\n",
            "/opt/conda/lib/python3.8/site-packages/datasets/load.py:2072: FutureWarning: 'use_auth_token' was deprecated in favor of 'token' in version 2.14.0 and will be removed in 3.0.0.\n",
            "You can remove this warning by passing 'token=False' instead.\n",
            "  warnings.warn(\n",
            "\n",
            "\n",
            "Evaluation Time:  1:12:27\n",
            "Valid Bleu 1:  0.5668     Valid Bleu 2: 0.416\n",
            "Valid Bleu 3:  0.3264     Valid Bleu 4:  0.2631\n",
            "Test Bleu 1:  0.5775     Test Bleu 2:  0.4189\n",
            "Test Bleu 3:  0.3231     Test Bleu 4:  0.2552\n",
            "\n",
            "\n",
            "You are resizing the embedding layer without providing a `pad_to_multiple_of` parameter. This means that the new embeding dimension will be 32101. This might induce some performance reduction as *Tensor Cores* will not be available. For more details  about this, or help on choosing the correct value for resizing, refer to this guide: https://docs.nvidia.com/deeplearning/performance/dl-performance-matrix-multiplication/index.html#requirements-tc\n",
            "/opt/conda/lib/python3.8/site-packages/datasets/load.py:2072: FutureWarning: 'use_auth_token' was deprecated in favor of 'token' in version 2.14.0 and will be removed in 3.0.0.\n",
            "You can remove this warning by passing 'token=False' instead.\n",
            "  warnings.warn(\n",
            "\n",
            "\n",
            "Evaluation Time:  1:11:35\n",
            "Valid Bleu 1:  0.5735     Valid Bleu 2: 0.4221\n",
            "Valid Bleu 3:  0.3317     Valid Bleu 4:  0.2679\n",
            "Test Bleu 1:  0.587     Test Bleu 2:  0.4273\n",
            "Test Bleu 3:  0.3304     Test Bleu 4:  0.2616\n",
            "\n",
            "\n",
            "You are resizing the embedding layer without providing a `pad_to_multiple_of` parameter. This means that the new embeding dimension will be 32101. This might induce some performance reduction as *Tensor Cores* will not be available. For more details  about this, or help on choosing the correct value for resizing, refer to this guide: https://docs.nvidia.com/deeplearning/performance/dl-performance-matrix-multiplication/index.html#requirements-tc\n",
            "/opt/conda/lib/python3.8/site-packages/datasets/load.py:2072: FutureWarning: 'use_auth_token' was deprecated in favor of 'token' in version 2.14.0 and will be removed in 3.0.0.\n",
            "You can remove this warning by passing 'token=False' instead.\n",
            "  warnings.warn(\n",
            "\n",
            "\n",
            "Evaluation Time:  1:10:36\n",
            "Valid Bleu 1:  0.5808     Valid Bleu 2: 0.4289\n",
            "Valid Bleu 3:  0.338     Valid Bleu 4:  0.2733\n",
            "Test Bleu 1:  0.5895     Test Bleu 2:  0.4308\n",
            "Test Bleu 3:  0.3341     Test Bleu 4:  0.265\n",
            "\n",
            "\n",
            "You are resizing the embedding layer without providing a `pad_to_multiple_of` parameter. This means that the new embeding dimension will be 32101. This might induce some performance reduction as *Tensor Cores* will not be available. For more details  about this, or help on choosing the correct value for resizing, refer to this guide: https://docs.nvidia.com/deeplearning/performance/dl-performance-matrix-multiplication/index.html#requirements-tc\n",
            "/opt/conda/lib/python3.8/site-packages/datasets/load.py:2072: FutureWarning: 'use_auth_token' was deprecated in favor of 'token' in version 2.14.0 and will be removed in 3.0.0.\n",
            "You can remove this warning by passing 'token=False' instead.\n",
            "  warnings.warn(\n",
            "\n",
            "\n",
            "Evaluation Time:  1:10:45\n",
            "Valid Bleu 1:  0.5819     Valid Bleu 2: 0.4305\n",
            "Valid Bleu 3:  0.3397     Valid Bleu 4:  0.2751\n",
            "Test Bleu 1:  0.5921     Test Bleu 2:  0.4337\n",
            "Test Bleu 3:  0.3369     Test Bleu 4:  0.2679\n",
            "\n",
            "\n",
            "You are resizing the embedding layer without providing a `pad_to_multiple_of` parameter. This means that the new embeding dimension will be 32101. This might induce some performance reduction as *Tensor Cores* will not be available. For more details  about this, or help on choosing the correct value for resizing, refer to this guide: https://docs.nvidia.com/deeplearning/performance/dl-performance-matrix-multiplication/index.html#requirements-tc\n",
            "/opt/conda/lib/python3.8/site-packages/datasets/load.py:2072: FutureWarning: 'use_auth_token' was deprecated in favor of 'token' in version 2.14.0 and will be removed in 3.0.0.\n",
            "You can remove this warning by passing 'token=False' instead.\n",
            "  warnings.warn(\n",
            "\n",
            "\n",
            "Evaluation Time:  1:10:59\n",
            "Valid Bleu 1:  0.5799     Valid Bleu 2: 0.4292\n",
            "Valid Bleu 3:  0.3388     Valid Bleu 4:  0.2745\n",
            "Test Bleu 1:  0.5937     Test Bleu 2:  0.4346\n",
            "Test Bleu 3:  0.3375     Test Bleu 4:  0.2681\n",
            "\n",
            "\n",
            "You are resizing the embedding layer without providing a `pad_to_multiple_of` parameter. This means that the new embeding dimension will be 32101. This might induce some performance reduction as *Tensor Cores* will not be available. For more details  about this, or help on choosing the correct value for resizing, refer to this guide: https://docs.nvidia.com/deeplearning/performance/dl-performance-matrix-multiplication/index.html#requirements-tc\n",
            "/opt/conda/lib/python3.8/site-packages/datasets/load.py:2072: FutureWarning: 'use_auth_token' was deprecated in favor of 'token' in version 2.14.0 and will be removed in 3.0.0.\n",
            "You can remove this warning by passing 'token=False' instead.\n",
            "  warnings.warn(\n",
            "\n",
            "\n",
            "Evaluation Time:  1:10:43\n",
            "Valid Bleu 1:  0.5828     Valid Bleu 2: 0.4315\n",
            "Valid Bleu 3:  0.341     Valid Bleu 4:  0.2766\n",
            "Test Bleu 1:  0.5935     Test Bleu 2:  0.4344\n",
            "Test Bleu 3:  0.3373     Test Bleu 4:  0.2679\n",
            "\n",
            "\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Waiting for W&B process to finish... \u001b[32m(success).\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: / 0.027 MB of 0.027 MB uploaded (0.000 MB deduped)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Run history:\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:  test_bleu_1 ▁▅▆▇██████\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:  test_bleu_2 ▁▅▆▇██████\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:  test_bleu_3 ▁▅▆▇██████\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:  test_bleu_4 ▁▄▆▇██████\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: valid_bleu_1 ▁▅▆▇██████\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: valid_bleu_2 ▁▅▆▇██████\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: valid_bleu_3 ▁▅▆▇██████\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: valid_bleu_4 ▁▅▆▇██████\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Run summary:\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:  test_bleu_1 0.59355\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:  test_bleu_2 0.43438\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:  test_bleu_3 0.33725\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:  test_bleu_4 0.26786\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: valid_bleu_1 0.58282\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: valid_bleu_2 0.43147\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: valid_bleu_3 0.34095\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: valid_bleu_4 0.27665\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: 🚀 View run \u001b[33mflan_t5_large_squad_qg_lora_r16_al32\u001b[0m at: \u001b[34m\u001b[4mhttps://wandb.ai/minseok0809/lmqg_qg_squad/runs/kumq9u8t\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Find logs at: \u001b[35m\u001b[1m./wandb/run-20230912_212132-kumq9u8t/logs\u001b[0m\n"
          ]
        }
      ],
      "source": [
        "!python -m lm-question-generation.lmqg.grid_searcher_flan_t5_large_squad_qg_lora_r16_al32_evaluation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "!python -m lm-question-generation.lmqg.grid_searcher_flan_t5_large_squad_qg_lora_r32_al32_training"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "!python -m lm-question-generation.lmqg.grid_searcher_flan_t5_large_squad_qg_lora_r32_al32_evaluation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "!python -m lm-question-generation.lmqg.grid_searcher_flan_t5_large_squad_qg_lora_r64_al32_training"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "!python -m lm-question-generation.lmqg.grid_searcher_flan_t5_large_squad_qg_lora_r64_al32_evaluation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mminseok0809\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: wandb version 0.15.10 is available!  To upgrade, please run:\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:  $ pip install wandb --upgrade\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.15.9\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Run data is saved locally in \u001b[35m\u001b[1m/workspace/wandb/run-20230914_002427-wl3hdu5d\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Run \u001b[1m`wandb offline`\u001b[0m to turn off syncing.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Syncing run \u001b[33mflan_t5_large_squad_qg_lora_r128_al32\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: ⭐️ View project at \u001b[34m\u001b[4mhttps://wandb.ai/minseok0809/lmqg_qg_squad\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: 🚀 View run at \u001b[34m\u001b[4mhttps://wandb.ai/minseok0809/lmqg_qg_squad/runs/wl3hdu5d\u001b[0m\n",
            "/opt/conda/lib/python3.8/site-packages/transformers/models/auto/tokenization_auto.py:631: FutureWarning: The `use_auth_token` argument is deprecated and will be removed in v5 of Transformers.\n",
            "  warnings.warn(\n",
            "/opt/conda/lib/python3.8/site-packages/transformers/models/auto/configuration_auto.py:995: FutureWarning: The `use_auth_token` argument is deprecated and will be removed in v5 of Transformers.\n",
            "  warnings.warn(\n",
            "/opt/conda/lib/python3.8/site-packages/transformers/modeling_utils.py:2310: FutureWarning: The `use_auth_token` argument is deprecated and will be removed in v5 of Transformers.\n",
            "  warnings.warn(\n",
            "/opt/conda/lib/python3.8/site-packages/transformers/utils/hub.py:373: FutureWarning: The `use_auth_token` argument is deprecated and will be removed in v5 of Transformers.\n",
            "  warnings.warn(\n",
            "You are resizing the embedding layer without providing a `pad_to_multiple_of` parameter. This means that the new embeding dimension will be 32101. This might induce some performance reduction as *Tensor Cores* will not be available. For more details  about this, or help on choosing the correct value for resizing, refer to this guide: https://docs.nvidia.com/deeplearning/performance/dl-performance-matrix-multiplication/index.html#requirements-tc\n",
            "\n",
            "\n",
            "trainable model parameters: 37748736\n",
            "all model parameters: 820843520\n",
            "percentage of trainable model parameters: 4.60% \n",
            "\n",
            "/opt/conda/lib/python3.8/site-packages/datasets/load.py:2072: FutureWarning: 'use_auth_token' was deprecated in favor of 'token' in version 2.14.0 and will be removed in 3.0.0.\n",
            "You can remove this warning by passing 'token=False' instead.\n",
            "  warnings.warn(\n",
            "\n",
            "\n",
            "Epoch 1: 100%|██████████████████████████| 18792/18792 [1:07:04<00:00,  4.67it/s]\n",
            "Loss :   7.8668\n",
            "\n",
            "\n",
            "Epoch 2: 100%|██████████████████████████| 18792/18792 [1:07:03<00:00,  4.67it/s]\n",
            "Loss :   0.8468\n",
            "\n",
            "\n",
            "Epoch 3: 100%|██████████████████████████| 18792/18792 [1:07:07<00:00,  4.67it/s]\n",
            "Loss :   0.7767\n",
            "\n",
            "\n",
            "Epoch 4: 100%|██████████████████████████| 18792/18792 [1:07:09<00:00,  4.66it/s]\n",
            "Loss :   0.7464\n",
            "\n",
            "\n",
            "Epoch 5: 100%|██████████████████████████| 18792/18792 [1:07:09<00:00,  4.66it/s]\n",
            "Loss :   0.7289\n",
            "\n",
            "\n",
            "Epoch 6: 100%|██████████████████████████| 18792/18792 [1:07:08<00:00,  4.67it/s]\n",
            "Loss :   0.7183\n",
            "\n",
            "\n",
            "Epoch 7: 100%|██████████████████████████| 18792/18792 [1:07:03<00:00,  4.67it/s]\n",
            "Loss :   0.7088\n",
            "\n",
            "\n",
            "Epoch 8: 100%|██████████████████████████| 18792/18792 [1:07:05<00:00,  4.67it/s]\n",
            "Loss :   0.7014\n",
            "\n",
            "\n",
            "Epoch 9: 100%|██████████████████████████| 18792/18792 [1:07:01<00:00,  4.67it/s]\n",
            "Loss :   0.6944\n",
            "\n",
            "\n",
            "Epoch 10: 100%|█████████████████████████| 18792/18792 [1:07:09<00:00,  4.66it/s]\n",
            "Loss :   0.6875\n",
            "\n",
            "\n",
            "Epoch 11: 100%|█████████████████████████| 18792/18792 [1:07:07<00:00,  4.67it/s]\n",
            "Loss :   0.6799\n",
            "\n",
            "\n",
            "Epoch 12: 100%|█████████████████████████| 18792/18792 [1:07:06<00:00,  4.67it/s]\n",
            "Loss :   0.6683\n",
            "\n",
            "\n",
            "Epoch 13: 100%|█████████████████████████| 18792/18792 [1:07:02<00:00,  4.67it/s]\n",
            "Loss :   0.6477\n",
            "\n",
            "\n",
            "Epoch 14: 100%|█████████████████████████| 18792/18792 [1:06:59<00:00,  4.68it/s]\n",
            "Loss :   0.6341\n",
            "\n",
            "\n",
            "Epoch 15: 100%|█████████████████████████| 18792/18792 [1:07:05<00:00,  4.67it/s]\n",
            "Loss :   0.6253\n",
            "\n",
            "\n",
            "Epoch 16: 100%|█████████████████████████| 18792/18792 [1:07:08<00:00,  4.66it/s]\n",
            "Loss :   0.6188\n",
            "\n",
            "\n",
            "Epoch 17: 100%|█████████████████████████| 18792/18792 [1:07:03<00:00,  4.67it/s]\n",
            "Loss :   0.6138\n",
            "\n",
            "\n",
            "Epoch 18: 100%|█████████████████████████| 18792/18792 [1:07:06<00:00,  4.67it/s]\n",
            "Loss :   0.61\n",
            "\n",
            "\n",
            "Epoch 19: 100%|█████████████████████████| 18792/18792 [1:07:09<00:00,  4.66it/s]\n",
            "Loss :   0.6057\n",
            "\n",
            "\n",
            "Epoch 20: 100%|█████████████████████████| 18792/18792 [1:07:05<00:00,  4.67it/s]\n",
            "Loss :   0.6036\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Waiting for W&B process to finish... \u001b[32m(success).\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Run history:\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: loss █▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Run summary:\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: loss 0.6036\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: 🚀 View run \u001b[33mflan_t5_large_squad_qg_lora_r128_al32\u001b[0m at: \u001b[34m\u001b[4mhttps://wandb.ai/minseok0809/lmqg_qg_squad/runs/wl3hdu5d\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Find logs at: \u001b[35m\u001b[1m./wandb/run-20230914_002427-wl3hdu5d/logs\u001b[0m\n"
          ]
        }
      ],
      "source": [
        "!python -m lm-question-generation.lmqg.grid_searcher_flan_t5_large_squad_qg_lora_r128_al32_training"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mminseok0809\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: wandb version 0.15.10 is available!  To upgrade, please run:\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:  $ pip install wandb --upgrade\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.15.9\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Run data is saved locally in \u001b[35m\u001b[1m/workspace/wandb/run-20230914_224716-nh0carqx\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Run \u001b[1m`wandb offline`\u001b[0m to turn off syncing.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Syncing run \u001b[33mflan_t5_large_squad_qg_lora_r128_al32\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: ⭐️ View project at \u001b[34m\u001b[4mhttps://wandb.ai/minseok0809/lmqg_qg_squad\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: 🚀 View run at \u001b[34m\u001b[4mhttps://wandb.ai/minseok0809/lmqg_qg_squad/runs/nh0carqx\u001b[0m\n",
            "You are resizing the embedding layer without providing a `pad_to_multiple_of` parameter. This means that the new embeding dimension will be 32101. This might induce some performance reduction as *Tensor Cores* will not be available. For more details  about this, or help on choosing the correct value for resizing, refer to this guide: https://docs.nvidia.com/deeplearning/performance/dl-performance-matrix-multiplication/index.html#requirements-tc\n",
            "/opt/conda/lib/python3.8/site-packages/datasets/load.py:2072: FutureWarning: 'use_auth_token' was deprecated in favor of 'token' in version 2.14.0 and will be removed in 3.0.0.\n",
            "You can remove this warning by passing 'token=False' instead.\n",
            "  warnings.warn(\n",
            "\n",
            "\n",
            "Evaluation Time:  1:33:54\n",
            "Valid Bleu 1:  0.2003     Valid Bleu 2: 0.1098\n",
            "Valid Bleu 3:  0.0698     Valid Bleu 4:  0.0478\n",
            "Test Bleu 1:  0.2078     Test Bleu 2:  0.1148\n",
            "Test Bleu 3:  0.0719     Test Bleu 4:  0.0484\n",
            "\n",
            "\n",
            "You are resizing the embedding layer without providing a `pad_to_multiple_of` parameter. This means that the new embeding dimension will be 32101. This might induce some performance reduction as *Tensor Cores* will not be available. For more details  about this, or help on choosing the correct value for resizing, refer to this guide: https://docs.nvidia.com/deeplearning/performance/dl-performance-matrix-multiplication/index.html#requirements-tc\n",
            "/opt/conda/lib/python3.8/site-packages/datasets/load.py:2072: FutureWarning: 'use_auth_token' was deprecated in favor of 'token' in version 2.14.0 and will be removed in 3.0.0.\n",
            "You can remove this warning by passing 'token=False' instead.\n",
            "  warnings.warn(\n",
            "\n",
            "\n",
            "Evaluation Time:  1:33:00\n",
            "Valid Bleu 1:  0.2398     Valid Bleu 2: 0.1447\n",
            "Valid Bleu 3:  0.0982     Valid Bleu 4:  0.0707\n",
            "Test Bleu 1:  0.2399     Test Bleu 2:  0.1427\n",
            "Test Bleu 3:  0.0945     Test Bleu 4:  0.0665\n",
            "\n",
            "\n",
            "You are resizing the embedding layer without providing a `pad_to_multiple_of` parameter. This means that the new embeding dimension will be 32101. This might induce some performance reduction as *Tensor Cores* will not be available. For more details  about this, or help on choosing the correct value for resizing, refer to this guide: https://docs.nvidia.com/deeplearning/performance/dl-performance-matrix-multiplication/index.html#requirements-tc\n",
            "/opt/conda/lib/python3.8/site-packages/datasets/load.py:2072: FutureWarning: 'use_auth_token' was deprecated in favor of 'token' in version 2.14.0 and will be removed in 3.0.0.\n",
            "You can remove this warning by passing 'token=False' instead.\n",
            "  warnings.warn(\n",
            "\n",
            "\n",
            "Evaluation Time:  1:32:13\n",
            "Valid Bleu 1:  0.268     Valid Bleu 2: 0.1679\n",
            "Valid Bleu 3:  0.1173     Valid Bleu 4:  0.0861\n",
            "Test Bleu 1:  0.265     Test Bleu 2:  0.1636\n",
            "Test Bleu 3:  0.1115     Test Bleu 4:  0.0799\n",
            "\n",
            "\n",
            "You are resizing the embedding layer without providing a `pad_to_multiple_of` parameter. This means that the new embeding dimension will be 32101. This might induce some performance reduction as *Tensor Cores* will not be available. For more details  about this, or help on choosing the correct value for resizing, refer to this guide: https://docs.nvidia.com/deeplearning/performance/dl-performance-matrix-multiplication/index.html#requirements-tc\n",
            "/opt/conda/lib/python3.8/site-packages/datasets/load.py:2072: FutureWarning: 'use_auth_token' was deprecated in favor of 'token' in version 2.14.0 and will be removed in 3.0.0.\n",
            "You can remove this warning by passing 'token=False' instead.\n",
            "  warnings.warn(\n",
            "\n",
            "\n",
            "Evaluation Time:  1:31:37\n",
            "Valid Bleu 1:  0.2962     Valid Bleu 2: 0.1912\n",
            "Valid Bleu 3:  0.1363     Valid Bleu 4:  0.1015\n",
            "Test Bleu 1:  0.2898     Test Bleu 2:  0.1847\n",
            "Test Bleu 3:  0.129     Test Bleu 4:  0.0942\n",
            "\n",
            "\n",
            "You are resizing the embedding layer without providing a `pad_to_multiple_of` parameter. This means that the new embeding dimension will be 32101. This might induce some performance reduction as *Tensor Cores* will not be available. For more details  about this, or help on choosing the correct value for resizing, refer to this guide: https://docs.nvidia.com/deeplearning/performance/dl-performance-matrix-multiplication/index.html#requirements-tc\n",
            "/opt/conda/lib/python3.8/site-packages/datasets/load.py:2072: FutureWarning: 'use_auth_token' was deprecated in favor of 'token' in version 2.14.0 and will be removed in 3.0.0.\n",
            "You can remove this warning by passing 'token=False' instead.\n",
            "  warnings.warn(\n",
            "\n",
            "\n",
            "Evaluation Time:  1:29:48\n",
            "Valid Bleu 1:  0.3303     Valid Bleu 2: 0.2188\n",
            "Valid Bleu 3:  0.1593     Valid Bleu 4:  0.1204\n",
            "Test Bleu 1:  0.3221     Test Bleu 2:  0.2103\n",
            "Test Bleu 3:  0.1494     Test Bleu 4:  0.1105\n",
            "\n",
            "\n",
            "You are resizing the embedding layer without providing a `pad_to_multiple_of` parameter. This means that the new embeding dimension will be 32101. This might induce some performance reduction as *Tensor Cores* will not be available. For more details  about this, or help on choosing the correct value for resizing, refer to this guide: https://docs.nvidia.com/deeplearning/performance/dl-performance-matrix-multiplication/index.html#requirements-tc\n",
            "/opt/conda/lib/python3.8/site-packages/datasets/load.py:2072: FutureWarning: 'use_auth_token' was deprecated in favor of 'token' in version 2.14.0 and will be removed in 3.0.0.\n",
            "You can remove this warning by passing 'token=False' instead.\n",
            "  warnings.warn(\n",
            "\n",
            "\n",
            "Evaluation Time:  1:25:41\n",
            "Valid Bleu 1:  0.4132     Valid Bleu 2: 0.2874\n",
            "Valid Bleu 3:  0.2165     Valid Bleu 4:  0.1685\n",
            "Test Bleu 1:  0.405     Test Bleu 2:  0.2772\n",
            "Test Bleu 3:  0.2039     Test Bleu 4:  0.1548\n",
            "\n",
            "\n",
            "You are resizing the embedding layer without providing a `pad_to_multiple_of` parameter. This means that the new embeding dimension will be 32101. This might induce some performance reduction as *Tensor Cores* will not be available. For more details  about this, or help on choosing the correct value for resizing, refer to this guide: https://docs.nvidia.com/deeplearning/performance/dl-performance-matrix-multiplication/index.html#requirements-tc\n",
            "/opt/conda/lib/python3.8/site-packages/datasets/load.py:2072: FutureWarning: 'use_auth_token' was deprecated in favor of 'token' in version 2.14.0 and will be removed in 3.0.0.\n",
            "You can remove this warning by passing 'token=False' instead.\n",
            "  warnings.warn(\n",
            "\n",
            "\n",
            "Evaluation Time:  1:23:19\n",
            "Valid Bleu 1:  0.4659     Valid Bleu 2: 0.3328\n",
            "Valid Bleu 3:  0.2556     Valid Bleu 4:  0.2021\n",
            "Test Bleu 1:  0.4672     Test Bleu 2:  0.3285\n",
            "Test Bleu 3:  0.2474     Test Bleu 4:  0.1917\n",
            "\n",
            "\n",
            "You are resizing the embedding layer without providing a `pad_to_multiple_of` parameter. This means that the new embeding dimension will be 32101. This might induce some performance reduction as *Tensor Cores* will not be available. For more details  about this, or help on choosing the correct value for resizing, refer to this guide: https://docs.nvidia.com/deeplearning/performance/dl-performance-matrix-multiplication/index.html#requirements-tc\n",
            "/opt/conda/lib/python3.8/site-packages/datasets/load.py:2072: FutureWarning: 'use_auth_token' was deprecated in favor of 'token' in version 2.14.0 and will be removed in 3.0.0.\n",
            "You can remove this warning by passing 'token=False' instead.\n",
            "  warnings.warn(\n",
            "\n",
            "\n",
            "Evaluation Time:  1:19:10\n",
            "Valid Bleu 1:  0.5195     Valid Bleu 2: 0.3764\n",
            "Valid Bleu 3:  0.2924     Valid Bleu 4:  0.2338\n",
            "Test Bleu 1:  0.5243     Test Bleu 2:  0.3744\n",
            "Test Bleu 3:  0.2854     Test Bleu 4:  0.2231\n",
            "\n",
            "\n",
            "You are resizing the embedding layer without providing a `pad_to_multiple_of` parameter. This means that the new embeding dimension will be 32101. This might induce some performance reduction as *Tensor Cores* will not be available. For more details  about this, or help on choosing the correct value for resizing, refer to this guide: https://docs.nvidia.com/deeplearning/performance/dl-performance-matrix-multiplication/index.html#requirements-tc\n",
            "/opt/conda/lib/python3.8/site-packages/datasets/load.py:2072: FutureWarning: 'use_auth_token' was deprecated in favor of 'token' in version 2.14.0 and will be removed in 3.0.0.\n",
            "You can remove this warning by passing 'token=False' instead.\n",
            "  warnings.warn(\n",
            "\n",
            "\n",
            "Evaluation Time:  1:17:00\n",
            "Valid Bleu 1:  0.5435     Valid Bleu 2: 0.3966\n",
            "Valid Bleu 3:  0.3096     Valid Bleu 4:  0.2485\n",
            "Test Bleu 1:  0.5558     Test Bleu 2:  0.4015\n",
            "Test Bleu 3:  0.3087     Test Bleu 4:  0.2432\n",
            "\n",
            "\n",
            "You are resizing the embedding layer without providing a `pad_to_multiple_of` parameter. This means that the new embeding dimension will be 32101. This might induce some performance reduction as *Tensor Cores* will not be available. For more details  about this, or help on choosing the correct value for resizing, refer to this guide: https://docs.nvidia.com/deeplearning/performance/dl-performance-matrix-multiplication/index.html#requirements-tc\n",
            "/opt/conda/lib/python3.8/site-packages/datasets/load.py:2072: FutureWarning: 'use_auth_token' was deprecated in favor of 'token' in version 2.14.0 and will be removed in 3.0.0.\n",
            "You can remove this warning by passing 'token=False' instead.\n",
            "  warnings.warn(\n",
            "\n",
            "\n",
            "Evaluation Time:  1:15:15\n",
            "Valid Bleu 1:  0.563     Valid Bleu 2: 0.4133\n",
            "Valid Bleu 3:  0.3241     Valid Bleu 4:  0.2611\n",
            "Test Bleu 1:  0.573     Test Bleu 2:  0.4153\n",
            "Test Bleu 3:  0.3202     Test Bleu 4:  0.2529\n",
            "\n",
            "\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Waiting for W&B process to finish... \u001b[32m(success).\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Run history:\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:  test_bleu_1 ▁▂▂▃▃▅▆▇██\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:  test_bleu_2 ▁▂▂▃▃▅▆▇██\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:  test_bleu_3 ▁▂▂▃▃▅▆▇██\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:  test_bleu_4 ▁▂▂▃▃▅▆▇██\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: valid_bleu_1 ▁▂▂▃▄▅▆▇██\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: valid_bleu_2 ▁▂▂▃▄▅▆▇██\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: valid_bleu_3 ▁▂▂▃▃▅▆▇██\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: valid_bleu_4 ▁▂▂▃▃▅▆▇██\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Run summary:\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:  test_bleu_1 0.57295\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:  test_bleu_2 0.41527\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:  test_bleu_3 0.32022\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:  test_bleu_4 0.25286\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: valid_bleu_1 0.56298\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: valid_bleu_2 0.41332\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: valid_bleu_3 0.32409\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: valid_bleu_4 0.26114\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: 🚀 View run \u001b[33mflan_t5_large_squad_qg_lora_r128_al32\u001b[0m at: \u001b[34m\u001b[4mhttps://wandb.ai/minseok0809/lmqg_qg_squad/runs/nh0carqx\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Find logs at: \u001b[35m\u001b[1m./wandb/run-20230914_224716-nh0carqx/logs\u001b[0m\n"
          ]
        }
      ],
      "source": [
        "!python -m lm-question-generation.lmqg.grid_searcher_flan_t5_large_squad_qg_lora_r128_al32_evaluation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "wandb.finish()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Flan T5 XL Model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Original Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "!python -m lm-question-generation.lmqg.grid_searcher_flan_t5_xl_squad_qg"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "wandb.finish()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Lora Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "!python -m lm-question-generation.lmqg.grid_searcher_flan_t5_xl_squad_qg_lora_r1_al32_training "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "!python -m lm-question-generation.lmqg.grid_searcher_flan_t5_xl_squad_qg_lora_r1_al32_evaluation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "!python -m lm-question-generation.lmqg.grid_searcher_flan_t5_xl_squad_qg_lora_r2_al32_training "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "!python -m lm-question-generation.lmqg.grid_searcher_flan_t5_xl_squad_qg_lora_r2_al32_evaluation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "!python -m lm-question-generation.lmqg.grid_searcher_flan_t5_xl_squad_qg_lora_r4_al32_training "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "!python -m lm-question-generation.lmqg.grid_searcher_flan_t5_xl_squad_qg_lora_r4_al32_evaluation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "!python -m lm-question-generation.lmqg.grid_searcher_flan_t5_xl_squad_qg_lora_r8_al32_training "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "!python -m lm-question-generation.lmqg.grid_searcher_flan_t5_xl_squad_qg_lora_r8_al32_evaluation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "!python -m lm-question-generation.lmqg.grid_searcher_flan_t5_xl_squad_qg_lora_r16_al32_training "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "!python -m lm-question-generation.lmqg.grid_searcher_flan_t5_xl_squad_qg_lora_r16_al32_evaluation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "!python -m lm-question-generation.lmqg.grid_searcher_flan_t5_xl_squad_qg_lora_r32_al32_training "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "!python -m lm-question-generation.lmqg.grid_searcher_flan_t5_xl_squad_qg_lora_r32_al32_evaluation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mminseok0809\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: wandb version 0.15.10 is available!  To upgrade, please run:\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:  $ pip install wandb --upgrade\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.15.9\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Run data is saved locally in \u001b[35m\u001b[1m/workspace/wandb/run-20230907_041650-qyi075cc\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Run \u001b[1m`wandb offline`\u001b[0m to turn off syncing.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Syncing run \u001b[33mflan_t5_xl_squad_qg_lora_r64_al32\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: ⭐️ View project at \u001b[34m\u001b[4mhttps://wandb.ai/minseok0809/lmqg_qg_squad\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: 🚀 View run at \u001b[34m\u001b[4mhttps://wandb.ai/minseok0809/lmqg_qg_squad/runs/qyi075cc\u001b[0m\n",
            "/opt/conda/lib/python3.8/site-packages/transformers/models/auto/tokenization_auto.py:631: FutureWarning: The `use_auth_token` argument is deprecated and will be removed in v5 of Transformers.\n",
            "  warnings.warn(\n",
            "/opt/conda/lib/python3.8/site-packages/transformers/models/auto/configuration_auto.py:995: FutureWarning: The `use_auth_token` argument is deprecated and will be removed in v5 of Transformers.\n",
            "  warnings.warn(\n",
            "/opt/conda/lib/python3.8/site-packages/transformers/modeling_utils.py:2310: FutureWarning: The `use_auth_token` argument is deprecated and will be removed in v5 of Transformers.\n",
            "  warnings.warn(\n",
            "Loading checkpoint shards: 100%|██████████████████| 2/2 [00:04<00:00,  2.12s/it]\n",
            "/opt/conda/lib/python3.8/site-packages/transformers/utils/hub.py:373: FutureWarning: The `use_auth_token` argument is deprecated and will be removed in v5 of Transformers.\n",
            "  warnings.warn(\n",
            "You are resizing the embedding layer without providing a `pad_to_multiple_of` parameter. This means that the new embeding dimension will be 32101. This might induce some performance reduction as *Tensor Cores* will not be available. For more details  about this, or help on choosing the correct value for resizing, refer to this guide: https://docs.nvidia.com/deeplearning/performance/dl-performance-matrix-multiplication/index.html#requirements-tc\n",
            "\n",
            "\n",
            "trainable model parameters: 37748736\n",
            "all model parameters: 2887395328\n",
            "percentage of trainable model parameters: 1.31% \n",
            "\n",
            "/opt/conda/lib/python3.8/site-packages/datasets/load.py:2072: FutureWarning: 'use_auth_token' was deprecated in favor of 'token' in version 2.14.0 and will be removed in 3.0.0.\n",
            "You can remove this warning by passing 'token=False' instead.\n",
            "  warnings.warn(\n",
            "\n",
            "\n",
            "Epoch 1: 100%|██████████████████████████| 37585/37585 [2:41:13<00:00,  3.89it/s]\n",
            "Loss :   2.2366\n",
            "\n",
            "\n",
            "Epoch 2: 100%|██████████████████████████| 37585/37585 [2:41:34<00:00,  3.88it/s]\n",
            "Loss :   0.5769\n",
            "\n",
            "\n",
            "Epoch 3: 100%|██████████████████████████| 37585/37585 [2:41:32<00:00,  3.88it/s]\n",
            "Loss :   0.562\n",
            "\n",
            "\n",
            "Epoch 4: 100%|██████████████████████████| 37585/37585 [2:41:41<00:00,  3.87it/s]\n",
            "Loss :   0.5532\n",
            "\n",
            "\n",
            "Epoch 5: 100%|██████████████████████████| 37585/37585 [2:41:50<00:00,  3.87it/s]\n",
            "Loss :   0.5462\n",
            "\n",
            "\n",
            "Epoch 6: 100%|██████████████████████████| 37585/37585 [2:42:23<00:00,  3.86it/s]\n",
            "Loss :   0.5398\n",
            "\n",
            "\n",
            "Epoch 7: 100%|██████████████████████████| 37585/37585 [2:42:29<00:00,  3.86it/s]\n",
            "Loss :   0.5337\n",
            "\n",
            "\n",
            "Epoch 8: 100%|██████████████████████████| 37585/37585 [2:41:42<00:00,  3.87it/s]\n",
            "Loss :   0.5287\n",
            "\n",
            "\n",
            "Epoch 9: 100%|██████████████████████████| 37585/37585 [2:41:54<00:00,  3.87it/s]\n",
            "Loss :   0.5238\n",
            "\n",
            "\n",
            "Epoch 10: 100%|█████████████████████████| 37585/37585 [2:42:07<00:00,  3.86it/s]\n",
            "Loss :   0.5193\n",
            "\n",
            "\n",
            "Epoch 11: 100%|█████████████████████████| 37585/37585 [2:42:16<00:00,  3.86it/s]\n",
            "Loss :   0.5152\n",
            "\n",
            "\n",
            "Epoch 12: 100%|█████████████████████████| 37585/37585 [2:42:09<00:00,  3.86it/s]\n",
            "Loss :   0.5116\n",
            "\n",
            "\n",
            "Epoch 13: 100%|█████████████████████████| 37585/37585 [2:42:07<00:00,  3.86it/s]\n",
            "Loss :   0.5076\n",
            "\n",
            "\n",
            "Epoch 14: 100%|█████████████████████████| 37585/37585 [2:41:57<00:00,  3.87it/s]\n",
            "Loss :   0.5038\n",
            "\n",
            "\n",
            "Epoch 15: 100%|█████████████████████████| 37585/37585 [2:42:06<00:00,  3.86it/s]\n",
            "Loss :   0.5006\n",
            "\n",
            "\n",
            "Epoch 16: 100%|█████████████████████████| 37585/37585 [2:42:04<00:00,  3.87it/s]\n",
            "Loss :   0.4973\n",
            "\n",
            "\n",
            "Epoch 17: 100%|█████████████████████████| 37585/37585 [2:42:01<00:00,  3.87it/s]\n",
            "Loss :   0.4939\n",
            "\n",
            "\n",
            "Epoch 18: 100%|█████████████████████████| 37585/37585 [2:42:09<00:00,  3.86it/s]\n",
            "Loss :   0.4908\n",
            "\n",
            "\n",
            "Epoch 19: 100%|█████████████████████████| 37585/37585 [2:42:00<00:00,  3.87it/s]\n",
            "Loss :   0.487\n",
            "\n",
            "\n",
            "Epoch 20: 100%|█████████████████████████| 37585/37585 [2:42:01<00:00,  3.87it/s]\n",
            "Loss :   0.4842\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Waiting for W&B process to finish... \u001b[32m(success).\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Run history:\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: loss █▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Run summary:\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: loss 0.48415\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: 🚀 View run \u001b[33mflan_t5_xl_squad_qg_lora_r64_al32\u001b[0m at: \u001b[34m\u001b[4mhttps://wandb.ai/minseok0809/lmqg_qg_squad/runs/qyi075cc\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Find logs at: \u001b[35m\u001b[1m./wandb/run-20230907_041650-qyi075cc/logs\u001b[0m\n"
          ]
        }
      ],
      "source": [
        "!python -m lm-question-generation.lmqg.grid_searcher_flan_t5_xl_squad_qg_lora_r64_al32_training "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mminseok0809\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: wandb version 0.15.10 is available!  To upgrade, please run:\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:  $ pip install wandb --upgrade\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.15.9\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Run data is saved locally in \u001b[35m\u001b[1m/workspace/wandb/run-20230909_101731-hpo46zsx\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Run \u001b[1m`wandb offline`\u001b[0m to turn off syncing.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Syncing run \u001b[33mflan_t5_xl_squad_qg_lora_r64_al32\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: ⭐️ View project at \u001b[34m\u001b[4mhttps://wandb.ai/minseok0809/lmqg_qg_squad\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: 🚀 View run at \u001b[34m\u001b[4mhttps://wandb.ai/minseok0809/lmqg_qg_squad/runs/hpo46zsx\u001b[0m\n",
            "Loading checkpoint shards: 100%|██████████████████| 2/2 [00:04<00:00,  2.08s/it]\n",
            "You are resizing the embedding layer without providing a `pad_to_multiple_of` parameter. This means that the new embeding dimension will be 32101. This might induce some performance reduction as *Tensor Cores* will not be available. For more details  about this, or help on choosing the correct value for resizing, refer to this guide: https://docs.nvidia.com/deeplearning/performance/dl-performance-matrix-multiplication/index.html#requirements-tc\n",
            "/opt/conda/lib/python3.8/site-packages/datasets/load.py:2072: FutureWarning: 'use_auth_token' was deprecated in favor of 'token' in version 2.14.0 and will be removed in 3.0.0.\n",
            "You can remove this warning by passing 'token=False' instead.\n",
            "  warnings.warn(\n",
            "100%|███████████████████████████████████| 11877/11877 [00:04<00:00, 2662.27it/s]\n",
            "100%|███████████████████████████████████| 10570/10570 [00:04<00:00, 2447.08it/s]\n",
            "\n",
            "\n",
            "Evaluation Time:  3:11:08\n",
            "Valid Bleu 1:  0.2885     Valid Bleu 2: 0.1916\n",
            "Valid Bleu 3:  0.1382     Valid Bleu 4:  0.1039\n",
            "Test Bleu 1:  0.295     Test Bleu 2:  0.1934\n",
            "Test Bleu 3:  0.1366     Test Bleu 4:  0.1\n",
            "\n",
            "\n",
            "Loading checkpoint shards: 100%|██████████████████| 2/2 [00:04<00:00,  2.04s/it]\n",
            "You are resizing the embedding layer without providing a `pad_to_multiple_of` parameter. This means that the new embeding dimension will be 32101. This might induce some performance reduction as *Tensor Cores* will not be available. For more details  about this, or help on choosing the correct value for resizing, refer to this guide: https://docs.nvidia.com/deeplearning/performance/dl-performance-matrix-multiplication/index.html#requirements-tc\n",
            "/opt/conda/lib/python3.8/site-packages/datasets/load.py:2072: FutureWarning: 'use_auth_token' was deprecated in favor of 'token' in version 2.14.0 and will be removed in 3.0.0.\n",
            "You can remove this warning by passing 'token=False' instead.\n",
            "  warnings.warn(\n",
            "\n",
            "\n",
            "Evaluation Time:  2:37:02\n",
            "Valid Bleu 1:  0.488     Valid Bleu 2: 0.3513\n",
            "Valid Bleu 3:  0.272     Valid Bleu 4:  0.2172\n",
            "Test Bleu 1:  0.4961     Test Bleu 2:  0.3547\n",
            "Test Bleu 3:  0.2705     Test Bleu 4:  0.2118\n",
            "\n",
            "\n",
            "Loading checkpoint shards: 100%|██████████████████| 2/2 [00:04<00:00,  2.04s/it]\n",
            "You are resizing the embedding layer without providing a `pad_to_multiple_of` parameter. This means that the new embeding dimension will be 32101. This might induce some performance reduction as *Tensor Cores* will not be available. For more details  about this, or help on choosing the correct value for resizing, refer to this guide: https://docs.nvidia.com/deeplearning/performance/dl-performance-matrix-multiplication/index.html#requirements-tc\n",
            "/opt/conda/lib/python3.8/site-packages/datasets/load.py:2072: FutureWarning: 'use_auth_token' was deprecated in favor of 'token' in version 2.14.0 and will be removed in 3.0.0.\n",
            "You can remove this warning by passing 'token=False' instead.\n",
            "  warnings.warn(\n",
            "\n",
            "\n",
            "Evaluation Time:  2:30:12\n",
            "Valid Bleu 1:  0.5344     Valid Bleu 2: 0.3902\n",
            "Valid Bleu 3:  0.3052     Valid Bleu 4:  0.2459\n",
            "Test Bleu 1:  0.5464     Test Bleu 2:  0.3962\n",
            "Test Bleu 3:  0.3059     Test Bleu 4:  0.242\n",
            "\n",
            "\n",
            "Loading checkpoint shards: 100%|██████████████████| 2/2 [00:04<00:00,  2.06s/it]\n",
            "You are resizing the embedding layer without providing a `pad_to_multiple_of` parameter. This means that the new embeding dimension will be 32101. This might induce some performance reduction as *Tensor Cores* will not be available. For more details  about this, or help on choosing the correct value for resizing, refer to this guide: https://docs.nvidia.com/deeplearning/performance/dl-performance-matrix-multiplication/index.html#requirements-tc\n",
            "/opt/conda/lib/python3.8/site-packages/datasets/load.py:2072: FutureWarning: 'use_auth_token' was deprecated in favor of 'token' in version 2.14.0 and will be removed in 3.0.0.\n",
            "You can remove this warning by passing 'token=False' instead.\n",
            "  warnings.warn(\n",
            "\n",
            "\n",
            "Evaluation Time:  2:27:21\n",
            "Valid Bleu 1:  0.5491     Valid Bleu 2: 0.4035\n",
            "Valid Bleu 3:  0.3174     Valid Bleu 4:  0.2566\n",
            "Test Bleu 1:  0.5597     Test Bleu 2:  0.4081\n",
            "Test Bleu 3:  0.3163     Test Bleu 4:  0.2512\n",
            "\n",
            "\n",
            "Loading checkpoint shards: 100%|██████████████████| 2/2 [00:04<00:00,  2.04s/it]\n",
            "You are resizing the embedding layer without providing a `pad_to_multiple_of` parameter. This means that the new embeding dimension will be 32101. This might induce some performance reduction as *Tensor Cores* will not be available. For more details  about this, or help on choosing the correct value for resizing, refer to this guide: https://docs.nvidia.com/deeplearning/performance/dl-performance-matrix-multiplication/index.html#requirements-tc\n",
            "/opt/conda/lib/python3.8/site-packages/datasets/load.py:2072: FutureWarning: 'use_auth_token' was deprecated in favor of 'token' in version 2.14.0 and will be removed in 3.0.0.\n",
            "You can remove this warning by passing 'token=False' instead.\n",
            "  warnings.warn(\n",
            "\n",
            "\n",
            "Evaluation Time:  2:24:59\n",
            "Valid Bleu 1:  0.5678     Valid Bleu 2: 0.4202\n",
            "Valid Bleu 3:  0.3318     Valid Bleu 4:  0.2693\n",
            "Test Bleu 1:  0.5797     Test Bleu 2:  0.4252\n",
            "Test Bleu 3:  0.3308     Test Bleu 4:  0.2633\n",
            "\n",
            "\n",
            "Loading checkpoint shards: 100%|██████████████████| 2/2 [00:04<00:00,  2.05s/it]\n",
            "You are resizing the embedding layer without providing a `pad_to_multiple_of` parameter. This means that the new embeding dimension will be 32101. This might induce some performance reduction as *Tensor Cores* will not be available. For more details  about this, or help on choosing the correct value for resizing, refer to this guide: https://docs.nvidia.com/deeplearning/performance/dl-performance-matrix-multiplication/index.html#requirements-tc\n",
            "/opt/conda/lib/python3.8/site-packages/datasets/load.py:2072: FutureWarning: 'use_auth_token' was deprecated in favor of 'token' in version 2.14.0 and will be removed in 3.0.0.\n",
            "You can remove this warning by passing 'token=False' instead.\n",
            "  warnings.warn(\n",
            "\n",
            "\n",
            "Evaluation Time:  2:21:12\n",
            "Valid Bleu 1:  0.5814     Valid Bleu 2: 0.4319\n",
            "Valid Bleu 3:  0.3424     Valid Bleu 4:  0.2788\n",
            "Test Bleu 1:  0.5991     Test Bleu 2:  0.4427\n",
            "Test Bleu 3:  0.3465     Test Bleu 4:  0.2774\n",
            "\n",
            "\n",
            "Loading checkpoint shards: 100%|██████████████████| 2/2 [00:03<00:00,  1.92s/it]\n",
            "You are resizing the embedding layer without providing a `pad_to_multiple_of` parameter. This means that the new embeding dimension will be 32101. This might induce some performance reduction as *Tensor Cores* will not be available. For more details  about this, or help on choosing the correct value for resizing, refer to this guide: https://docs.nvidia.com/deeplearning/performance/dl-performance-matrix-multiplication/index.html#requirements-tc\n",
            "/opt/conda/lib/python3.8/site-packages/datasets/load.py:2072: FutureWarning: 'use_auth_token' was deprecated in favor of 'token' in version 2.14.0 and will be removed in 3.0.0.\n",
            "You can remove this warning by passing 'token=False' instead.\n",
            "  warnings.warn(\n",
            "\n",
            "\n",
            "Evaluation Time:  2:22:59\n",
            "Valid Bleu 1:  0.5792     Valid Bleu 2: 0.4309\n",
            "Valid Bleu 3:  0.3417     Valid Bleu 4:  0.2781\n",
            "Test Bleu 1:  0.5955     Test Bleu 2:  0.4394\n",
            "Test Bleu 3:  0.3435     Test Bleu 4:  0.2743\n",
            "\n",
            "\n",
            "Loading checkpoint shards: 100%|██████████████████| 2/2 [00:03<00:00,  1.91s/it]\n",
            "You are resizing the embedding layer without providing a `pad_to_multiple_of` parameter. This means that the new embeding dimension will be 32101. This might induce some performance reduction as *Tensor Cores* will not be available. For more details  about this, or help on choosing the correct value for resizing, refer to this guide: https://docs.nvidia.com/deeplearning/performance/dl-performance-matrix-multiplication/index.html#requirements-tc\n",
            "/opt/conda/lib/python3.8/site-packages/datasets/load.py:2072: FutureWarning: 'use_auth_token' was deprecated in favor of 'token' in version 2.14.0 and will be removed in 3.0.0.\n",
            "You can remove this warning by passing 'token=False' instead.\n",
            "  warnings.warn(\n",
            "\n",
            "\n",
            "Evaluation Time:  2:22:55\n",
            "Valid Bleu 1:  0.5839     Valid Bleu 2: 0.435\n",
            "Valid Bleu 3:  0.3449     Valid Bleu 4:  0.2806\n",
            "Test Bleu 1:  0.5989     Test Bleu 2:  0.4421\n",
            "Test Bleu 3:  0.3458     Test Bleu 4:  0.2762\n",
            "\n",
            "\n",
            "Loading checkpoint shards: 100%|██████████████████| 2/2 [00:03<00:00,  1.92s/it]\n",
            "You are resizing the embedding layer without providing a `pad_to_multiple_of` parameter. This means that the new embeding dimension will be 32101. This might induce some performance reduction as *Tensor Cores* will not be available. For more details  about this, or help on choosing the correct value for resizing, refer to this guide: https://docs.nvidia.com/deeplearning/performance/dl-performance-matrix-multiplication/index.html#requirements-tc\n",
            "/opt/conda/lib/python3.8/site-packages/datasets/load.py:2072: FutureWarning: 'use_auth_token' was deprecated in favor of 'token' in version 2.14.0 and will be removed in 3.0.0.\n",
            "You can remove this warning by passing 'token=False' instead.\n",
            "  warnings.warn(\n",
            "\n",
            "\n",
            "Evaluation Time:  2:24:33\n",
            "Valid Bleu 1:  0.577     Valid Bleu 2: 0.4284\n",
            "Valid Bleu 3:  0.3392     Valid Bleu 4:  0.2758\n",
            "Test Bleu 1:  0.593     Test Bleu 2:  0.4363\n",
            "Test Bleu 3:  0.3406     Test Bleu 4:  0.2719\n",
            "\n",
            "\n",
            "Loading checkpoint shards: 100%|██████████████████| 2/2 [00:03<00:00,  1.97s/it]\n",
            "You are resizing the embedding layer without providing a `pad_to_multiple_of` parameter. This means that the new embeding dimension will be 32101. This might induce some performance reduction as *Tensor Cores* will not be available. For more details  about this, or help on choosing the correct value for resizing, refer to this guide: https://docs.nvidia.com/deeplearning/performance/dl-performance-matrix-multiplication/index.html#requirements-tc\n",
            "/opt/conda/lib/python3.8/site-packages/datasets/load.py:2072: FutureWarning: 'use_auth_token' was deprecated in favor of 'token' in version 2.14.0 and will be removed in 3.0.0.\n",
            "You can remove this warning by passing 'token=False' instead.\n",
            "  warnings.warn(\n",
            "\n",
            "\n",
            "Evaluation Time:  2:22:59\n",
            "Valid Bleu 1:  0.5835     Valid Bleu 2: 0.4336\n",
            "Valid Bleu 3:  0.3434     Valid Bleu 4:  0.279\n",
            "Test Bleu 1:  0.6     Test Bleu 2:  0.4426\n",
            "Test Bleu 3:  0.3461     Test Bleu 4:  0.2763\n",
            "\n",
            "\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Waiting for W&B process to finish... \u001b[32m(success).\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: | 0.028 MB of 0.028 MB uploaded (0.000 MB deduped)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Run history:\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:  test_bleu_1 ▁▆▇▇██████\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:  test_bleu_2 ▁▆▇▇██████\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:  test_bleu_3 ▁▅▇▇▇█████\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:  test_bleu_4 ▁▅▇▇▇█████\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: valid_bleu_1 ▁▆▇▇██████\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: valid_bleu_2 ▁▆▇▇██████\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: valid_bleu_3 ▁▆▇▇██████\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: valid_bleu_4 ▁▅▇▇██████\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Run summary:\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:  test_bleu_1 0.60004\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:  test_bleu_2 0.44259\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:  test_bleu_3 0.34606\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:  test_bleu_4 0.27634\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: valid_bleu_1 0.58352\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: valid_bleu_2 0.43363\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: valid_bleu_3 0.34337\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: valid_bleu_4 0.27902\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: 🚀 View run \u001b[33mflan_t5_xl_squad_qg_lora_r64_al32\u001b[0m at: \u001b[34m\u001b[4mhttps://wandb.ai/minseok0809/lmqg_qg_squad/runs/hpo46zsx\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Find logs at: \u001b[35m\u001b[1m./wandb/run-20230909_101731-hpo46zsx/logs\u001b[0m\n"
          ]
        }
      ],
      "source": [
        "!python -m lm-question-generation.lmqg.grid_searcher_flan_t5_xl_squad_qg_lora_r64_al32_evaluation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "!python -m lm-question-generation.lmqg.grid_searcher_flan_t5_xl_squad_qg_lora_r128_al32_training "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "!python -m lm-question-generation.lmqg.grid_searcher_flan_t5_xl_squad_qg_lora_r128_al32_evaluation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "wandb.finish()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Flan T5 XXL Model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Original Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "!python -m lm-question-generation.lmqg.grid_searcher_flan_t5_xxl_squad_qg"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {},
      "outputs": [],
      "source": [
        "wandb.finish()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Lora Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "!python -m lm-question-generation.lmqg.grid_searcher_flan_t5_xxl_squad_qg_lora_r1_al32_training "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "!python -m lm-question-generation.lmqg.grid_searcher_flan_t5_xxl_squad_qg_lora_r1_al32_evaluation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "!python -m lm-question-generation.lmqg.grid_searcher_flan_t5_xxl_squad_qg_lora_r8_al32_training "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "!python -m lm-question-generation.lmqg.grid_searcher_flan_t5_xxl_squad_qg_lora_r8_al32_evaluation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "wandb.finish()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "erRMsEx-zJbX"
      },
      "source": [
        "## T5 Small Model Grid Search"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from lmqg import GridSearcher\n",
        "\n",
        "trainer = GridSearcher(\n",
        "    checkpoint_dir='tmp_ckpt_t5_small_0819',\n",
        "    dataset_path='lmqg/qg_squad',\n",
        "    model='t5-small',\n",
        "    epoch=3,\n",
        "    epoch_partial=1,\n",
        "    batch=64,\n",
        "    n_max_config=5,\n",
        "    gradient_accumulation_steps=[2], \n",
        "    lr=[1e-04],\n",
        "    label_smoothing=[0, 0.15]\n",
        ")\n",
        "trainer.run()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Grid Search\n",
        "<br>gradient_accumulation_steps=[2, 4], \n",
        "<br>lr=[1e-04, 5e-04, 1e-03],\n",
        "<br>label_smoothing=[0, 0.15]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "The number of model: \n",
        "<br>gradient_accumulation_steps * lr * label_smoothing \n",
        "<br>3 * 2 * 2 = 12"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 58,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Best Model of T5 Small\n",
            "\n",
            "_name_or_path : tmp_ckpt/model_cghqta/epoch_5\n",
            "model : t5-small\n",
            "epoch : 12\n",
            "batch : 64\n",
            "lr : 0.0005  [Grid Search Result]\n",
            "gradient_accumulation_steps : 4  [Grid Search Result]\n",
            "label_smoothing : 0.15  [Grid Search Result]\n"
          ]
        }
      ],
      "source": [
        "with open('tmp_ckpt_t5_small_0818/best_model/config.json', 'r') as f:\n",
        "    t5_small_best_model_config = json.load(f)\n",
        "\n",
        "with open('tmp_ckpt_t5_small_0818/best_model/trainer_config.json', 'r') as f:\n",
        "    t5_small_best_model_hyperparameter_search = json.load(f)\n",
        "\n",
        "hyperparameters = ['model', 'epoch', 'batch',\n",
        "                   'lr', 'gradient_accumulation_steps', 'label_smoothing']\n",
        "grid_serach_hyperparameter = ['lr', 'gradient_accumulation_steps', 'label_smoothing']\n",
        "\n",
        "print(colored(\"Best Model of T5 Small\", attrs=['bold']))\n",
        "print()\n",
        "for value, key in t5_small_best_model_config.items():\n",
        "    if '_name_or_path' in value:\n",
        "        print(\"{} : {}\".format(value, key))   \n",
        "    \n",
        "for value, key in t5_small_best_model_hyperparameter_search.items():\n",
        "    if any(hyperparameter in value for hyperparameter in hyperparameters):\n",
        "        if any(hyperparameter in value for hyperparameter in grid_serach_hyperparameter):\n",
        "            print(\"{} : {}  [Grid Search Result]\".format(value, key))\n",
        "        else:\n",
        "            print(\"{} : {}\".format(value, key))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Best T5 SmallModel"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### End2end QAG"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# lmqg/t5-small-squad-qag\n",
        "CUDA_VISIBLE_DEVICES=\"0\"\n",
        "\n",
        "!python -m lm-question-generation.lmqg.grid_searcher_t5_small_squad_qag \\\n",
        "#    --checkpoint_dir='tmp_ckpt_t5_small_squad_qag_0821' \\\n",
        "#    --dataset_path='lmqg/qg_squadshifts' \\\n",
        "#    --dataset_name='all' \\\n",
        "#    --model='t5-small' \\\n",
        "#    --epoch=15 \\\n",
        "#    --epoch_partial=5 \\\n",
        "#    --batch=64 \\\n",
        "#    --n_max_config=5 \\\n",
        "#    --gradient_accumulation_steps=[4] \\\n",
        "#    --lr=[5e-04] \\\n",
        "#    --label_smoothing=[0, 0.15] \\\n",
        "#    --language=\"en\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Multitask QAG"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "CUDA_VISIBLE_DEVICES=\"0\"\n",
        "\n",
        "!python -m lm-question-generation.lmqg.grid_searcher_t5_small_squad_qg_ae \\\n",
        "#    --checkpoint_dir='tmp_ckpt_t5_small_squad_qg_ae_0821 \\\n",
        "#    --dataset_path='lmqg/qg_squadshifts' \\\n",
        "#    --dataset_name='all' \\\n",
        "#    --model='t5-small' \\\n",
        "#    --epoch=15 \\\n",
        "#    --epoch_partial=5 \\\n",
        "#    --batch=64 \\\n",
        "#    --n_max_config=5 \\\n",
        "#    --gradient_accumulation_steps=[4] \\\n",
        "#    --lr=[5e-04] \\\n",
        "#    --label_smoothing=[0, 0.15] \\\n",
        "#    --language=\"en\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Pipeline QAG"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "CUDA_VISIBLE_DEVICES=\"0\"\n",
        "\n",
        "!python -m lm-question-generation.lmqg.grid_searcher_t5_small_squad_qg \\\n",
        "#    --checkpoint_dir='tmp_ckpt_t5_small_squad_qg_0821 \\\n",
        "#    --dataset_path='lmqg/t5-small-squad-qg' \\\n",
        "#    --dataset_name='all' \\\n",
        "#    --model='t5-small' \\\n",
        "#    --epoch=15 \\\n",
        "#    --epoch_partial=5 \\\n",
        "#    --batch=64 \\\n",
        "#    --n_max_config=5 \\\n",
        "#    --gradient_accumulation_steps=[4] \\\n",
        "#    --lr=[5e-04] \\\n",
        "#    --label_smoothing=[0, 0.15] \\\n",
        "#    --language=\"en\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Source"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "[lmqg/t5-small-squad-qa](https://huggingface.co/lmqg/t5-small-squad-qa)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.12"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
