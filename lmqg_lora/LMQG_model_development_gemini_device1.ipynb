{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "teHzLo4owK3j"
      },
      "source": [
        "## LMQG Model Development (Gemini Device 1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "<b>Model</b>\n",
        "<br>T5 Small / BART Base / T5 Base / T5 Large / BART Large\n",
        "<br>Gold QA (i.e., the model using the human-labeled gold\n",
        "annotations)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "<b>QAG approaches</b>\n",
        "<br>End2Endv / MultiTask / Pipeline"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "<b>Dataset</b>\n",
        "<br>SQuADShifts (Amazon / Wiki / NYT / Reddit)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "<b>Experiment</b>\n",
        "<br>All / Amazon / Wiki / NYT / Reddit"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "L6m9o9YV0j7O"
      },
      "outputs": [],
      "source": [
        "%pip install lmqg\n",
        "%pip install peft\n",
        "%pip install easydict\n",
        "%pip install termcolor\n",
        "%pip install openpyxl\n",
        "%pip install ipywidgets\n",
        "!python -m spacy download en"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "XrYqvzLjZwev"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import json\n",
        "import torch\n",
        "from pprint import pprint\n",
        "# from termcolor import coloredg\n",
        "from lmqg import TransformersQG"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "True\n",
            "2\n",
            "NVIDIA RTX A6000\n"
          ]
        }
      ],
      "source": [
        "print(torch.cuda.is_available())\n",
        "print(torch.cuda.device_count())\n",
        "print(torch.cuda.get_device_name(torch.cuda.current_device()))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'/'"
            ]
          },
          "execution_count": 4,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "pwd"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "/workspace\n"
          ]
        }
      ],
      "source": [
        "cd workspace"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [],
      "source": [
        "import torch\n",
        "torch.cuda.empty_cache()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {},
      "outputs": [],
      "source": [
        "import torch, gc\n",
        "gc.collect()\n",
        "torch.cuda.empty_cache()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {},
      "outputs": [],
      "source": [
        "os.environ[\"CUDA_DEVICE_ORDER\"]=\"PCI_BUS_ID\"\n",
        "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"1\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mminseok0809\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "execution_count": 9,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import wandb\n",
        "\n",
        "wandb.login()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Flan T5 Small Model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Original Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "!python -m lm-question-generation.lmqg.grid_searcher_flan_t5_small_squad_qg"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {},
      "outputs": [],
      "source": [
        "wandb.finish()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Lora Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "!python -m lm-question-generation.lmqg.grid_searcher_flan_t5_small_squad_qg_lora_r8_al16"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "!python -m lm-question-generation.lmqg.grid_searcher_flan_t5_small_squad_qg_lora_r16_al16"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "!python -m lm-question-generation.lmqg.grid_searcher_flan_t5_small_squad_qg_lora_r32_al16"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "!python -m lm-question-generation.lmqg.grid_searcher_flan_t5_small_squad_qg_lora_r64_al16"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "!python -m lm-question-generation.lmqg.grid_searcher_flan_t5_small_squad_qg_lora_r128_al16"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "!python -m lm-question-generation.lmqg.grid_searcher_flan_t5_small_squad_qg_lora_r8_al32"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "!python -m lm-question-generation.lmqg.grid_searcher_flan_t5_small_squad_qg_lora_r16_al32"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "!python -m lm-question-generation.lmqg.grid_searcher_flan_t5_small_squad_qg_lora_r32_al32"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "!python -m lm-question-generation.lmqg.grid_searcher_flan_t5_small_squad_qg_lora_r64_al32"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "!python -m lm-question-generation.lmqg.grid_searcher_flan_t5_small_squad_qg_lora_r128_al32"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {},
      "outputs": [],
      "source": [
        "wandb.finish()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Flan T5 Large Model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Original Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "!python -m lm-question-generation.lmqg.grid_searcher_flan_t5_large_squad_qg"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "wandb.finish()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Lora Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "!python -m lm-question-generation.lmqg.grid_searcher_flan_t5_large_squad_qg_lora_r1_al32_training"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "!python -m lm-question-generation.lmqg.grid_searcher_flan_t5_large_squad_qg_lora_r1_al32_evaluation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "!python -m lm-question-generation.lmqg.grid_searcher_flan_t5_large_squad_qg_lora_r2_al32_training"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "!python -m lm-question-generation.lmqg.grid_searcher_flan_t5_large_squad_qg_lora_r2_al32_evaluation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "!python -m lm-question-generation.lmqg.grid_searcher_flan_t5_large_squad_qg_lora_r4_al32_training"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "!python -m lm-question-generation.lmqg.grid_searcher_flan_t5_large_squad_qg_lora_r4_al32_evaluation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "!python -m lm-question-generation.lmqg.grid_searcher_flan_t5_large_squad_qg_lora_r8_al32_training"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "!python -m lm-question-generation.lmqg.grid_searcher_flan_t5_large_squad_qg_lora_r8_al32_evaluation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "!python -m lm-question-generation.lmqg.grid_searcher_flan_t5_large_squad_qg_lora_r16_al32_training"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "!python -m lm-question-generation.lmqg.grid_searcher_flan_t5_large_squad_qg_lora_r16_al32_evaluation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "!python -m lm-question-generation.lmqg.grid_searcher_flan_t5_large_squad_qg_lora_r32_al32_training"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "!python -m lm-question-generation.lmqg.grid_searcher_flan_t5_large_squad_qg_lora_r32_al32_evaluation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "!python -m lm-question-generation.lmqg.grid_searcher_flan_t5_large_squad_qg_lora_r64_al32_training"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "!python -m lm-question-generation.lmqg.grid_searcher_flan_t5_large_squad_qg_lora_r64_al32_evaluation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "!python -m lm-question-generation.lmqg.grid_searcher_flan_t5_large_squad_qg_lora_r128_al32_training"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "!python -m lm-question-generation.lmqg.grid_searcher_flan_t5_large_squad_qg_lora_r128_al32_evaluation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "wandb.finish()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Flan T5 XL Model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Original Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "!python -m lm-question-generation.lmqg.grid_searcher_flan_t5_xl_squad_qg"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "wandb.finish()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Lora Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "!python -m lm-question-generation.lmqg.grid_searcher_flan_t5_xl_squad_qg_lora_r1_al32_training "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "!python -m lm-question-generation.lmqg.grid_searcher_flan_t5_xl_squad_qg_lora_r1_al32_evaluation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "!python -m lm-question-generation.lmqg.grid_searcher_flan_t5_xl_squad_qg_lora_r2_al32_training "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "!python -m lm-question-generation.lmqg.grid_searcher_flan_t5_xl_squad_qg_lora_r2_al32_evaluation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "!python -m lm-question-generation.lmqg.grid_searcher_flan_t5_xl_squad_qg_lora_r4_al32_training "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "!python -m lm-question-generation.lmqg.grid_searcher_flan_t5_xl_squad_qg_lora_r4_al32_evaluation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mminseok0809\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: wandb version 0.15.10 is available!  To upgrade, please run:\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:  $ pip install wandb --upgrade\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.15.9\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Run data is saved locally in \u001b[35m\u001b[1m/workspace/wandb/run-20230907_041811-h5n96agh\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Run \u001b[1m`wandb offline`\u001b[0m to turn off syncing.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Syncing run \u001b[33mflan_t5_xl_squad_qg_lora_r8_al32\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: ‚≠êÔ∏è View project at \u001b[34m\u001b[4mhttps://wandb.ai/minseok0809/lmqg_qg_squad\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: üöÄ View run at \u001b[34m\u001b[4mhttps://wandb.ai/minseok0809/lmqg_qg_squad/runs/h5n96agh\u001b[0m\n",
            "Loading checkpoint shards: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2/2 [00:13<00:00,  6.75s/it]\n",
            "\n",
            "\n",
            "trainable model parameters: 4718592\n",
            "all model parameters: 2854365184\n",
            "percentage of trainable model parameters: 0.17% \n",
            "\n",
            "\n",
            "\n",
            "Epoch 1: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 18792/18792 [5:14:05<00:00,  1.00s/it]\n",
            "Loss :   3.8386\n",
            "\n",
            "\n",
            "Epoch 2: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 18792/18792 [5:14:24<00:00,  1.00s/it]\n",
            "Loss :   0.6054\n",
            "\n",
            "\n",
            "Epoch 3: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 18792/18792 [5:14:30<00:00,  1.00s/it]\n",
            "Loss :   0.5799\n",
            "\n",
            "\n",
            "Epoch 4: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 18792/18792 [5:14:20<00:00,  1.00s/it]\n",
            "Loss :   0.5699\n",
            "\n",
            "\n",
            "Epoch 5: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 18792/18792 [5:14:34<00:00,  1.00s/it]\n",
            "Loss :   0.5646\n",
            "\n",
            "\n",
            "Epoch 6: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 18792/18792 [5:14:50<00:00,  1.01s/it]\n",
            "Loss :   0.5596\n",
            "\n",
            "\n",
            "Epoch 7: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 18792/18792 [5:14:49<00:00,  1.01s/it]\n",
            "Loss :   0.5533\n",
            "\n",
            "\n",
            "Epoch 8: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 18792/18792 [5:14:41<00:00,  1.00s/it]\n",
            "Loss :   0.5491\n",
            "\n",
            "\n",
            "Epoch 9: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 18792/18792 [5:14:50<00:00,  1.01s/it]\n",
            "Loss :   0.545\n",
            "\n",
            "\n",
            "Epoch 10: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 18792/18792 [5:14:55<00:00,  1.01s/it]\n",
            "Loss :   0.5413\n",
            "\n",
            "\n",
            "Epoch 11: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 18792/18792 [5:14:46<00:00,  1.01s/it]\n",
            "Loss :   0.5377\n",
            "\n",
            "\n",
            "Epoch 12: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 18792/18792 [5:14:48<00:00,  1.01s/it]\n",
            "Loss :   0.5343\n",
            "\n",
            "\n",
            "Epoch 13: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 18792/18792 [5:14:37<00:00,  1.00s/it]\n",
            "Loss :   0.5306\n",
            "\n",
            "\n",
            "Epoch 14: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 18792/18792 [5:14:49<00:00,  1.01s/it]\n",
            "Loss :   0.5277\n",
            "\n",
            "\n",
            "Epoch 15: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 18792/18792 [5:14:57<00:00,  1.01s/it]\n",
            "Loss :   0.5242\n",
            "\n",
            "\n",
            "Epoch 16: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 18792/18792 [5:15:09<00:00,  1.01s/it]\n",
            "Loss :   0.521\n",
            "\n",
            "\n",
            "Epoch 17: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 18792/18792 [5:15:13<00:00,  1.01s/it]\n",
            "Loss :   0.5186\n",
            "\n",
            "\n",
            "Epoch 18: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 18792/18792 [5:15:11<00:00,  1.01s/it]\n",
            "Loss :   0.5161\n",
            "\n",
            "\n",
            "Epoch 19: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 18792/18792 [5:15:19<00:00,  1.01s/it]\n",
            "Loss :   0.5133\n",
            "\n",
            "\n",
            "Epoch 20: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 18792/18792 [5:15:14<00:00,  1.01s/it]\n",
            "Loss :   0.5109\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Waiting for W&B process to finish... \u001b[32m(success).\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Run history:\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: loss ‚ñà‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Run summary:\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: loss 0.51092\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: üöÄ View run \u001b[33mflan_t5_xl_squad_qg_lora_r8_al32\u001b[0m at: \u001b[34m\u001b[4mhttps://wandb.ai/minseok0809/lmqg_qg_squad/runs/h5n96agh\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Find logs at: \u001b[35m\u001b[1m./wandb/run-20230907_041811-h5n96agh/logs\u001b[0m\n"
          ]
        }
      ],
      "source": [
        "!python -m lm-question-generation.lmqg.grid_searcher_flan_t5_xl_squad_qg_lora_r8_al32_training "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mminseok0809\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: wandb version 0.15.10 is available!  To upgrade, please run:\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:  $ pip install wandb --upgrade\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.15.9\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Run data is saved locally in \u001b[35m\u001b[1m/workspace/wandb/run-20230912_004911-6nicome7\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Run \u001b[1m`wandb offline`\u001b[0m to turn off syncing.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Syncing run \u001b[33mflan_t5_xl_squad_qg_lora_r8_al32\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: ‚≠êÔ∏è View project at \u001b[34m\u001b[4mhttps://wandb.ai/minseok0809/lmqg_qg_squad\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: üöÄ View run at \u001b[34m\u001b[4mhttps://wandb.ai/minseok0809/lmqg_qg_squad/runs/6nicome7\u001b[0m\n",
            "Loading checkpoint shards: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2/2 [00:05<00:00,  2.52s/it]\n",
            "\n",
            "\n",
            "Evaluation Time:  2:59:50\n",
            "Valid Bleu 1:  0.2238     Valid Bleu 2: 0.1402\n",
            "Valid Bleu 3:  0.0967     Valid Bleu 4:  0.07\n",
            "Test Bleu 1:  0.2303     Test Bleu 2:  0.1423\n",
            "Test Bleu 3:  0.0964     Test Bleu 4:  0.0684\n",
            "\n",
            "\n",
            "Loading checkpoint shards: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2/2 [00:05<00:00,  2.52s/it]\n",
            "\n",
            "\n",
            "Evaluation Time:  2:59:39\n",
            "Valid Bleu 1:  0.2847     Valid Bleu 2: 0.1881\n",
            "Valid Bleu 3:  0.1354     Valid Bleu 4:  0.1014\n",
            "Test Bleu 1:  0.2876     Test Bleu 2:  0.1876\n",
            "Test Bleu 3:  0.1323     Test Bleu 4:  0.0968\n",
            "\n",
            "\n",
            "Loading checkpoint shards: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2/2 [00:05<00:00,  2.52s/it]\n",
            "\n",
            "\n",
            "Evaluation Time:  2:43:21\n",
            "Valid Bleu 1:  0.466     Valid Bleu 2: 0.3322\n",
            "Valid Bleu 3:  0.2551     Valid Bleu 4:  0.2022\n",
            "Test Bleu 1:  0.4781     Test Bleu 2:  0.3386\n",
            "Test Bleu 3:  0.2561     Test Bleu 4:  0.1991\n",
            "\n",
            "\n",
            "Loading checkpoint shards: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2/2 [00:04<00:00,  2.50s/it]\n",
            "\n",
            "\n",
            "Evaluation Time:  2:36:55\n",
            "Valid Bleu 1:  0.5343     Valid Bleu 2: 0.3894\n",
            "Valid Bleu 3:  0.3043     Valid Bleu 4:  0.2446\n",
            "Test Bleu 1:  0.5488     Test Bleu 2:  0.3972\n",
            "Test Bleu 3:  0.3063     Test Bleu 4:  0.242\n",
            "\n",
            "\n",
            "Loading checkpoint shards: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2/2 [00:05<00:00,  2.51s/it]\n",
            "\n",
            "\n",
            "Evaluation Time:  2:33:00\n",
            "Valid Bleu 1:  0.556     Valid Bleu 2: 0.409\n",
            "Valid Bleu 3:  0.3218     Valid Bleu 4:  0.2604\n",
            "Test Bleu 1:  0.5687     Test Bleu 2:  0.4146\n",
            "Test Bleu 3:  0.3218     Test Bleu 4:  0.2558\n",
            "\n",
            "\n",
            "Loading checkpoint shards: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2/2 [00:04<00:00,  2.46s/it]\n",
            "\n",
            "\n",
            "Evaluation Time:  2:31:56\n",
            "Valid Bleu 1:  0.5643     Valid Bleu 2: 0.4166\n",
            "Valid Bleu 3:  0.329     Valid Bleu 4:  0.2672\n",
            "Test Bleu 1:  0.5797     Test Bleu 2:  0.4244\n",
            "Test Bleu 3:  0.3303     Test Bleu 4:  0.2629\n",
            "\n",
            "\n",
            "Loading checkpoint shards: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2/2 [00:04<00:00,  2.10s/it]\n",
            "\n",
            "\n",
            "Evaluation Time:  2:29:43\n",
            "Valid Bleu 1:  0.5785     Valid Bleu 2: 0.4295\n",
            "Valid Bleu 3:  0.3402     Valid Bleu 4:  0.2766\n",
            "Test Bleu 1:  0.5959     Test Bleu 2:  0.439\n",
            "Test Bleu 3:  0.3429     Test Bleu 4:  0.2738\n",
            "\n",
            "\n",
            "Loading checkpoint shards: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2/2 [00:04<00:00,  2.48s/it]\n",
            "\n",
            "\n",
            "Evaluation Time:  2:29:58\n",
            "Valid Bleu 1:  0.5801     Valid Bleu 2: 0.4311\n",
            "Valid Bleu 3:  0.3417     Valid Bleu 4:  0.278\n",
            "Test Bleu 1:  0.5958     Test Bleu 2:  0.4393\n",
            "Test Bleu 3:  0.3432     Test Bleu 4:  0.2744\n",
            "\n",
            "\n",
            "Loading checkpoint shards: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2/2 [00:04<00:00,  2.12s/it]\n",
            "\n",
            "\n",
            "Evaluation Time:  2:30:59\n",
            "Valid Bleu 1:  0.5764     Valid Bleu 2: 0.4271\n",
            "Valid Bleu 3:  0.3377     Valid Bleu 4:  0.2741\n",
            "Test Bleu 1:  0.5903     Test Bleu 2:  0.4342\n",
            "Test Bleu 3:  0.339     Test Bleu 4:  0.2708\n",
            "\n",
            "\n",
            "Loading checkpoint shards: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2/2 [00:05<00:00,  2.53s/it]\n",
            "\n",
            "\n",
            "Evaluation Time:  2:31:33\n",
            "Valid Bleu 1:  0.5747     Valid Bleu 2: 0.4263\n",
            "Valid Bleu 3:  0.3374     Valid Bleu 4:  0.274\n",
            "Test Bleu 1:  0.5906     Test Bleu 2:  0.4352\n",
            "Test Bleu 3:  0.3399     Test Bleu 4:  0.2715\n",
            "\n",
            "\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Waiting for W&B process to finish... \u001b[32m(success).\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: | 0.005 MB of 0.020 MB uploaded (0.000 MB deduped)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Run history:\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:  test_bleu_1 ‚ñÅ‚ñÇ‚ñÜ‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:  test_bleu_2 ‚ñÅ‚ñÇ‚ñÜ‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:  test_bleu_3 ‚ñÅ‚ñÇ‚ñÜ‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:  test_bleu_4 ‚ñÅ‚ñÇ‚ñÖ‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: valid_bleu_1 ‚ñÅ‚ñÇ‚ñÜ‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: valid_bleu_2 ‚ñÅ‚ñÇ‚ñÜ‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: valid_bleu_3 ‚ñÅ‚ñÇ‚ñÜ‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: valid_bleu_4 ‚ñÅ‚ñÇ‚ñÖ‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Run summary:\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:  test_bleu_1 0.59058\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:  test_bleu_2 0.43518\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:  test_bleu_3 0.33993\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:  test_bleu_4 0.27151\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: valid_bleu_1 0.57469\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: valid_bleu_2 0.42627\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: valid_bleu_3 0.33744\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: valid_bleu_4 0.27401\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: üöÄ View run \u001b[33mflan_t5_xl_squad_qg_lora_r8_al32\u001b[0m at: \u001b[34m\u001b[4mhttps://wandb.ai/minseok0809/lmqg_qg_squad/runs/6nicome7\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Find logs at: \u001b[35m\u001b[1m./wandb/run-20230912_004911-6nicome7/logs\u001b[0m\n"
          ]
        }
      ],
      "source": [
        "!python -m lm-question-generation.lmqg.grid_searcher_flan_t5_xl_squad_qg_lora_r8_al32_evaluation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "!python -m lm-question-generation.lmqg.grid_searcher_flan_t5_xl_squad_qg_lora_r16_al32_training "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "!python -m lm-question-generation.lmqg.grid_searcher_flan_t5_xl_squad_qg_lora_r16_al32_evaluation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "!python -m lm-question-generation.lmqg.grid_searcher_flan_t5_xl_squad_qg_lora_r32_al32_training "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "!python -m lm-question-generation.lmqg.grid_searcher_flan_t5_xl_squad_qg_lora_r32_al32_evaluation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "!python -m lm-question-generation.lmqg.grid_searcher_flan_t5_xl_squad_qg_lora_r64_al32_training "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "!python -m lm-question-generation.lmqg.grid_searcher_flan_t5_xl_squad_qg_lora_r64_al32_evaluation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "!python -m lm-question-generation.lmqg.grid_searcher_flan_t5_xl_squad_qg_lora_r128_al32_training "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "!python -m lm-question-generation.lmqg.grid_searcher_flan_t5_xl_squad_qg_lora_r128_al32_evaluation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "wandb.finish()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Flan T5 XXL Model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Original Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "!python -m lm-question-generation.lmqg.grid_searcher_flan_t5_xxl_squad_qg"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {},
      "outputs": [],
      "source": [
        "wandb.finish()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Lora Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "!python -m lm-question-generation.lmqg.grid_searcher_flan_t5_xxl_squad_qg_lora_r1_al32_training "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "!python -m lm-question-generation.lmqg.grid_searcher_flan_t5_xxl_squad_qg_lora_r1_al32_evaluation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "!python -m lm-question-generation.lmqg.grid_searcher_flan_t5_xxl_squad_qg_lora_r8_al32_training "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "!python -m lm-question-generation.lmqg.grid_searcher_flan_t5_xxl_squad_qg_lora_r8_al32_evaluation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "wandb.finish()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "erRMsEx-zJbX"
      },
      "source": [
        "## T5 Small Model Grid Search"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from lmqg import GridSearcher\n",
        "\n",
        "trainer = GridSearcher(\n",
        "    checkpoint_dir='tmp_ckpt_t5_small_0819',\n",
        "    dataset_path='lmqg/qg_squad',\n",
        "    model='t5-small',\n",
        "    epoch=3,\n",
        "    epoch_partial=1,\n",
        "    batch=64,\n",
        "    n_max_config=5,\n",
        "    gradient_accumulation_steps=[2], \n",
        "    lr=[1e-04],\n",
        "    label_smoothing=[0, 0.15]\n",
        ")\n",
        "trainer.run()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Grid Search\n",
        "<br>gradient_accumulation_steps=[2, 4], \n",
        "<br>lr=[1e-04, 5e-04, 1e-03],\n",
        "<br>label_smoothing=[0, 0.15]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "The number of model: \n",
        "<br>gradient_accumulation_steps * lr * label_smoothing \n",
        "<br>3 * 2 * 2 = 12"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 58,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Best Model of T5 Small\n",
            "\n",
            "_name_or_path : tmp_ckpt/model_cghqta/epoch_5\n",
            "model : t5-small\n",
            "epoch : 12\n",
            "batch : 64\n",
            "lr : 0.0005  [Grid Search Result]\n",
            "gradient_accumulation_steps : 4  [Grid Search Result]\n",
            "label_smoothing : 0.15  [Grid Search Result]\n"
          ]
        }
      ],
      "source": [
        "with open('tmp_ckpt_t5_small_0818/best_model/config.json', 'r') as f:\n",
        "    t5_small_best_model_config = json.load(f)\n",
        "\n",
        "with open('tmp_ckpt_t5_small_0818/best_model/trainer_config.json', 'r') as f:\n",
        "    t5_small_best_model_hyperparameter_search = json.load(f)\n",
        "\n",
        "hyperparameters = ['model', 'epoch', 'batch',\n",
        "                   'lr', 'gradient_accumulation_steps', 'label_smoothing']\n",
        "grid_serach_hyperparameter = ['lr', 'gradient_accumulation_steps', 'label_smoothing']\n",
        "\n",
        "print(colored(\"Best Model of T5 Small\", attrs=['bold']))\n",
        "print()\n",
        "for value, key in t5_small_best_model_config.items():\n",
        "    if '_name_or_path' in value:\n",
        "        print(\"{} : {}\".format(value, key))   \n",
        "    \n",
        "for value, key in t5_small_best_model_hyperparameter_search.items():\n",
        "    if any(hyperparameter in value for hyperparameter in hyperparameters):\n",
        "        if any(hyperparameter in value for hyperparameter in grid_serach_hyperparameter):\n",
        "            print(\"{} : {}  [Grid Search Result]\".format(value, key))\n",
        "        else:\n",
        "            print(\"{} : {}\".format(value, key))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Best T5 SmallModel"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### End2end QAG"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# lmqg/t5-small-squad-qag\n",
        "CUDA_VISIBLE_DEVICES=\"0\"\n",
        "\n",
        "!python -m lm-question-generation.lmqg.grid_searcher_t5_small_squad_qag \\\n",
        "#    --checkpoint_dir='tmp_ckpt_t5_small_squad_qag_0821' \\\n",
        "#    --dataset_path='lmqg/qg_squadshifts' \\\n",
        "#    --dataset_name='all' \\\n",
        "#    --model='t5-small' \\\n",
        "#    --epoch=15 \\\n",
        "#    --epoch_partial=5 \\\n",
        "#    --batch=64 \\\n",
        "#    --n_max_config=5 \\\n",
        "#    --gradient_accumulation_steps=[4] \\\n",
        "#    --lr=[5e-04] \\\n",
        "#    --label_smoothing=[0, 0.15] \\\n",
        "#    --language=\"en\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Multitask QAG"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "CUDA_VISIBLE_DEVICES=\"0\"\n",
        "\n",
        "!python -m lm-question-generation.lmqg.grid_searcher_t5_small_squad_qg_ae \\\n",
        "#    --checkpoint_dir='tmp_ckpt_t5_small_squad_qg_ae_0821 \\\n",
        "#    --dataset_path='lmqg/qg_squadshifts' \\\n",
        "#    --dataset_name='all' \\\n",
        "#    --model='t5-small' \\\n",
        "#    --epoch=15 \\\n",
        "#    --epoch_partial=5 \\\n",
        "#    --batch=64 \\\n",
        "#    --n_max_config=5 \\\n",
        "#    --gradient_accumulation_steps=[4] \\\n",
        "#    --lr=[5e-04] \\\n",
        "#    --label_smoothing=[0, 0.15] \\\n",
        "#    --language=\"en\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Pipeline QAG"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "CUDA_VISIBLE_DEVICES=\"0\"\n",
        "\n",
        "!python -m lm-question-generation.lmqg.grid_searcher_t5_small_squad_qg \\\n",
        "#    --checkpoint_dir='tmp_ckpt_t5_small_squad_qg_0821 \\\n",
        "#    --dataset_path='lmqg/t5-small-squad-qg' \\\n",
        "#    --dataset_name='all' \\\n",
        "#    --model='t5-small' \\\n",
        "#    --epoch=15 \\\n",
        "#    --epoch_partial=5 \\\n",
        "#    --batch=64 \\\n",
        "#    --n_max_config=5 \\\n",
        "#    --gradient_accumulation_steps=[4] \\\n",
        "#    --lr=[5e-04] \\\n",
        "#    --label_smoothing=[0, 0.15] \\\n",
        "#    --language=\"en\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Source"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "[lmqg/t5-small-squad-qa](https://huggingface.co/lmqg/t5-small-squad-qa)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.12"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
